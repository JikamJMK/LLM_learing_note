{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 对未标记的数据进行预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.4.1\n",
      "tensorflow version: 2.17.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version   #检查本节所需要的库\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 本节利用循环训练和基础评估模型来对一个LLM进行预训练\n",
    "- 本节最后会将openai开源的预训练权重加载到模型中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.评估产生的文本的模型\n",
    "- 回顾先前写过的GPT模型\n",
    "- 讨论分析最基础的LLMs评估矩阵\n",
    "- 最后将这些评估矩阵应用到一个训练和检验的数据集中\n",
    "### 1.1 使用GPT来产生文本\n",
    "- 利用先前的代码来初始化一个GPT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel  #引入先前写的GPT模型\n",
    "\n",
    "GPT_CONFIG_124M = {  #模型基础参数\n",
    "    \"vocab_size\" : 50257,\n",
    "    \"context_length\" : 256,\n",
    "    \"emb_dim\" : 768,\n",
    "    \"n_heads\" : 12,\n",
    "    \"n_layers\" :12,\n",
    "    \"drop_rate\" : 0.1,\n",
    "    \"qkv_bias\" :False\n",
    "    \n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval() #评估的时候禁用dropout这些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们使用0.1的dropout率，不过现在很多LLMs在训练的时候不使用dropout了。\n",
    "- 先进的LLMs同样在线性层的时候不使用偏置向量 -- 通过设置 \" qkv_bias \" = False 来实现\n",
    "- 本次降低了context_length 到256，而不是先前GPT2模型对应的1024 （为了体谅一下电脑的算力..）之后也可以通过改配置到1024继续操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know,\" was one of the picture for a smile\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text,tokenizer):\n",
    "    encoded = tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) #加上批次的维度\n",
    "    return encoded_tensor  #因为后续模型处理的是张量，而不是列表。分词其直接处理最后产生的是一个token id 的列表，所以要进行转化\n",
    "\n",
    "def token_ids_to_text(token_ids,tokenizer):\n",
    "    flat = token_ids.squeeze(0) #去除批次维度\n",
    "    return tokenizer.decode(flat.tolist())    #将token ids 转化为文本，需要先去除批次，将所有文本权重位于第一的维度，再转化为列表，提供给decode方法使用\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\") #载入分词器\n",
    "\n",
    "token_ids = generate_text_simple( #将处理模型，文本tokens ， 要生成的tokens数，文本大小\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(start_context,tokenizer),\n",
    "    max_new_tokens = 10,\n",
    "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer)) #将生成的tokens转化为文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 由于没有对模型进行训练，当前产生的文本质量较差。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2计算文本的损失函数 ： 交叉熵损失(cross-entropy) 和 混乱度(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 假定此时我们有一个2个样例的输入 同时有一个对应的target（即，已知的你要生成的内容）\n",
    "- 注意由于input 和 target之间是由滑动窗口等实现的，所以两者的数据之间存在平移"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():       #表示不影响模型的梯度\n",
    "    logits = model(inputs)  #将输入作为参数，代入模型计算\n",
    "\n",
    "probas = torch.softmax(logits,dim = -1)  #得到概率分布\n",
    "print(probas.shape) #shape：(batch_size,nums_tokens,vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 按ch4结尾，使用argmax函数来处理概率分布。\n",
    "- softmax 函数处理过后，每一个token会产生一个50257维度的子向量（概率分布），然后使用argmax函数，可以获得最高概率所在的位置，这就是下一个预测的token id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas,dim = -1,keepdim = True)  #获得最高概率所在的位置\n",
    "print(\"Token IDs:\\n\",token_ids) #形状为(batch_size,num_token,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0],tokenizer)}\")  #输出理想的目标文本\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(),tokenizer)}\") #输出通过模型处理所得的文本\n",
    "#这里tokens_ids 的第一个批次形状是[[1][1][1]] / (num_tokens,1) -->所以用flatten先进行铺平，变为(num_tokens*1) \n",
    "# 发现两者并不相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 由于模型未训练，所以得到的结果与自己期待的结果相差很大。\n",
    "- 训练的目的就是让输出值尽可能地接近我们想要的值\n",
    "- 为了训练模型，我们需要知道它距离我们的期望到底有多远\n",
    "- token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1 :  tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2 :  tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx,[0,1,2],targets[text_idx]] #提取第0号批次，012（即前三个元素），targets[0]对应的句子中 token对应的id\n",
    "print(\"Text 1 : \",target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx,[0,1,2],targets[text_idx]]\n",
    "print(\"Text 2 : \",target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们的目标就是使得这些目标概率尽可能地接近1\n",
    "- 通过最优化的方式，利用概率的对数进行运算比直接利用概率本身更便捷，但超出了本书的范围了 ，具体参考：[L8.2 Logistic Regression Loss Function](https://www.youtube.com/watch?v=GxJe0DZvydM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "#计算所有概率的对数\n",
    "log_probas = torch.log(torch.cat((target_probas_1,target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "#计算概率对数的平均值\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目标是使得模型输出的概率尽可能地接近1 -- 即平均对数接近0 （取值范围为负无穷到0）\n",
    "- 在深度学习中，并不是利用这些负值的最大值，而是先将他转化为正值，然后希望获得最小的正值 。这里正值为负概率对数，又称为交叉熵损失(cross entropy loss)，是最常用的损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pytorch中已经实现了交叉熵函数(cross_entropy) 来实现上述功能\n",
    "<br></br>\n",
    "- 在应用交叉熵函数之前，先检查一下logits和targets的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape : torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# logits shape :(batch_size, num_tokens , vocab_size)\n",
    "print(\"Logits shape :\",logits.shape)\n",
    "\n",
    "#Targets shape:(batch_size,num_tokens) 这里最后target直接对应的是token id，不需要一个词典向量\n",
    "print(\"Targets shape:\",targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "#为使用cross_entropy函数，先将这些向量在batch_size 维度上进行摊平\n",
    "\n",
    "logits_flat = logits.flatten(0,1) #从第0维开始展平，到第1维结束\n",
    "targets_flat = targets.flatten() #将所有维度展平\n",
    "\n",
    "print(\"Flattened logits:\",logits_flat.shape)\n",
    "print(\"Flattened targets:\",targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- targets 对应的值即为token id ，同时它又代表着在logits 中我们想最大化的概率的索引\n",
    "- 可以利用` corss_entropy`函数来直接求得交叉熵损失 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat,targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LLM中一个和交叉熵损失相关的概念就是 混乱度(perplexity)\n",
    "- 混乱度就是交叉熵损失的指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 混乱度可以被理解为当前模型不确定下一部到底是xxx个单词中的哪一个，这里了xxx就是上文的48725\n",
    "- 也就是混乱度将概率分布，转化成了实际单词分布\n",
    "- 和交叉熵损失一样，混乱度越小，越接近实际分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3计算训练集和验证集损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 出于学习需求，成本和时间考虑，我们使用一个小的训练集进行训练。\n",
    "- 使用我们在ch2 中使用过的小数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path): #如果当前路径下不存在该文件\n",
    "    with urllib.request.urlopen(url) as response: #从url中获取该文件，并将内容按utf-8的形式解码\n",
    "        text_data = response.read().decode('utf-8') \n",
    "    with open(file_path,\"w\",encoding=\"utf-8\") as file: #将刚刚解码得到的文本，写入该路径下名为\"the-verdict.txt\"的文件中\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path,\"r\",encoding= \"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n",
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "print(text_data[:99]) #通过输出前100和后100个字符来快速检验一下\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters: 20479\n",
      "tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"characters:\",total_characters)\n",
    "print(\"tokens:\",total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 接下来，我们要将数据集分为训练集和验证集。并且使用ch2中写过的 数据加载器 为LLM训练提供一批一批的数据\n",
    "- 大部分的输入文本会作为训练集使用，剩下小部分的则作为后续的验证集\n",
    "- 先将文本进行分词 --> 将一个文本分成了大小为context_length 的块 -->然后按batchs再次分配（加上了shuffling，打乱数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "train_ratio = 0.90 #区分开训练集train和验证集validation所占文本比例\n",
    "split_idx = int(train_ratio*len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "#分别利用训练集文本和验证集的文本，通过数据加载器，来获得所需训练/校验用的数据\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size = 2,\n",
    "    max_length = GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride =  GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last = True,\n",
    "    shuffle = True,\n",
    "    num_workers = 0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size = 2,\n",
    "    max_length = GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride =  GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last = True,\n",
    "    shuffle = True,\n",
    "    num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 健全性检查\n",
    "if total_tokens*(train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader.\"\n",
    "          \"Try to lower the `GPT_CONFIG_124M[context_length]` or \"\n",
    "          \"increase the `training_ratio`\"\n",
    "         )\n",
    "if total_tokens*(1 - train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader.\"\n",
    "          \"Try to lower the `GPT_CONFIG_124M[context_length]` or \"\n",
    "          \"decrease the `training_ratio`\"\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上述我们采用的batch 只有 2（考虑到计算机性能的需求），并且数据较小，容易处理\n",
    "- 如果对于一些比较大的训练模型，一个可以选择的检查方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Valization loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape,y.shape)\n",
    "\n",
    "print(\"\\nValization loader:\")\n",
    "for x,y in val_loader:\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 另一个可以选择的检查方法(计算数据大小，判断是否在预期范围内)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch,target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch,target_batch in val_loader:\n",
    "    val_tokens +=input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\",train_tokens)\n",
    "print(\"Validation tokens:\",val_tokens)\n",
    "print(\"All tokens:\",train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 接下来，我们要实现一个实用函数来计算单个批次的交叉熵损失\n",
    "- 此外，还需要实现第二个实用函数来计算用户指定批次数目（在数据集中）的交叉熵损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch,target_batch,model,device):\n",
    "    input_batch,target_batch = input_batch.to(device),target_batch.to(device) #将输入批次，目标批次转化到当前使用的设备上（cpu/gpu）\n",
    "    logits = model(input_batch) #通过model模型，来获得概率分布前的数据(即再softmax一下就是概率分布)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1),target_batch.flatten()) #计算交叉熵损失\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
    "    total_loss = 0. #用于存放总的损失\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)  #如果玩家没有自定义批次数目，则默认处理数据加载器中的所有批次\n",
    "    else:\n",
    "        num_batches = min(num_batches,len(data_loader)) #如果自定义的批次数目高于加载器中所有的数目，则减少至只处理加载器中有的数目\n",
    "    for i,(input_batch,target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches: #只处理到num_batches数量的批次\n",
    "            loss = calc_loss_batch(input_batch,target_batch,model,device) #获取当前批次的交叉熵损失\n",
    "            total_loss += loss.item() #由于loss是一个张量（tensor），所以需要先提取出其中的数值标量\n",
    "        else :\n",
    "            break \n",
    "    return total_loss/num_batches #返回平均的交叉熵损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过设定 device ，确保LLM模型 数据都被加载到同一个设备上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  10.98758347829183\n",
      "Validation loss:  10.981106758117676\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #如果电脑支持cuda GPU操作，则使用GPU，反之CPU\n",
    "\n",
    "model.to(device) #不需要写 model = model.to(device) 这种重新赋值的方式。 因为 to 是进行的原地操作，不会返回值\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader,model,device)  #获取train训练集的交叉熵\n",
    "    val_loss = calc_loss_loader(val_loader,model,device) #获取校验集的交叉熵\n",
    "\n",
    "print(\"Training loss: \",train_loss)\n",
    "print(\"Validation loss: \",val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 截止目前，已经实现了文本生成（利用GPT模型）\n",
    "- 文本评估（利用交叉熵损失/混乱度）\n",
    "- 分成训练集和校验集进行计算交叉熵损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.训练LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 本节实现对LLM的训练代码。\n",
    "- 目前下面实现的是一个简单的训练函数。如果需要更先进的工具，参考附件D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):  #optimizer 是用于模型优化的优化器 ， num_epochs 是训练的轮次数 ，eval_freq 评估频率 ， eval_iter 评估中使用的批次数量\n",
    "\n",
    "    #初始化列表，来追踪训练集损失，验证集损失，模型训练过程中已经处理过的token数量。\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    #记录训练过程中处理的token数和全局训练步数\n",
    "    tokens_seen, global_step = 0, -1  \n",
    "\n",
    "    # 主要的训练循环\n",
    "    for epoch in range(num_epochs): #按指定的训练轮次数进行训练\n",
    "        model.train()  # 将模型设置为训练模式。\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # 重置之前循环中的损失梯度\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device) #计算当前的交叉熵损失\n",
    "            loss.backward() # 通过反向传播，计算损失的梯度\n",
    "            optimizer.step() # 利用损失的梯度来更新模型\n",
    "            tokens_seen += input_batch.numel() #处理的tokens数增加\n",
    "            global_step += 1 #全部训练步数增加1\n",
    "\n",
    "            # 可选评估步骤\n",
    "            if global_step % eval_freq == 0:  #每进行eval_freq（评估频率）步数\n",
    "                train_loss, val_loss = evaluate_model(    #调用评估模型 计算训练集损失和验证集损失\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)  #将计算所得的损失添加到列表中\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen) #将到了评估频率为止经过的所有tokens数加入到列表中。\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        generate_and_print_sample(  #在每一轮训练后打印一下文本\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen  #最终返回训练集列表，验证集列表，所有检测过的tokens数量\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter): #定义评估模型所需要的函数\n",
    "    model.eval() #将模型切换为评估模式\n",
    "    with torch.no_grad(): #评估的时候，禁用梯度模式 \n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter) #计算训练集损失\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter) #计算验证集损失\n",
    "    model.train() #将模型重新切换为训练模式\n",
    "    return train_loss, val_loss #返回训练集损失和验证集损失\n",
    "\n",
    " \n",
    "def generate_and_print_sample(model, tokenizer, device, start_context): #定义一个简易的生成打印函数\n",
    "    model.eval() #将模型切换为评估模型\n",
    "    context_size = model.pos_emb.weight.shape[0]  #获取文本的大小。每次生成一个token，最多参考前面这么多的token数目\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device) #将起始上下文文本编码为token ids\n",
    "    with torch.no_grad(): #禁用梯度模式\n",
    "        token_ids = generate_text_simple(   #传入模型，提供的起始文本编码结果，要产生的新词数目，限制参考的文本大小\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)  #将模型产生的文本解码。\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format 对输出文本进行格式化。将所有\\n转换为空格，使得输出在同一行。\n",
    "    model.train() #转化为评估模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上面定义了训练函数，评估函数和文本生成函数。\n",
    "- 接下来使用上面的函数进行LLM训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 10.157, Val loss 10.263\n",
      "Ep 1 (Step 000005): Train loss 8.739, Val loss 8.986\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 2 (Step 000010): Train loss 7.894, Val loss 8.125\n",
      "Ep 2 (Step 000015): Train loss 7.065, Val loss 7.388\n",
      "Every effort moves you, the, the the the the the the the the the the the the the the, the the the, the, the the the the the the the the the the the the the the the the, the the the the the the the the the\n",
      "Ep 3 (Step 000020): Train loss 6.385, Val loss 6.900\n",
      "Ep 3 (Step 000025): Train loss 5.874, Val loss 6.596\n",
      "Every effort moves you, and, and the the, and, and, and, and the, and, and the, and, and, and, and, and, and the, and, and, and, and the, and the, and, and,\n",
      "Ep 4 (Step 000030): Train loss 5.284, Val loss 6.434\n",
      "Ep 4 (Step 000035): Train loss 4.692, Val loss 6.279\n",
      "Every effort moves you, and I had been the picture--I to the picture.   \"I was the, and I had been the picture to the the, and I had been, and I had been, and, and I had been. I had\n",
      "Ep 5 (Step 000040): Train loss 4.386, Val loss 6.253\n",
      "Every effort moves you know it was not to the picture--I--I had a little of a.               I had been the, in the, and I, and I had been the, in\n",
      "Ep 6 (Step 000045): Train loss 3.861, Val loss 6.229\n",
      "Ep 6 (Step 000050): Train loss 3.416, Val loss 6.193\n",
      "Every effort moves you know it was not to the picture.        \"I was--I--and it.     \"--as I had been.   \" a little a little the--and I had\n",
      "Ep 7 (Step 000055): Train loss 3.075, Val loss 6.159\n",
      "Ep 7 (Step 000060): Train loss 2.515, Val loss 6.144\n",
      "Every effort moves you know.\" \" a little.\"   \"I had the last--and it was to me--and, I felt to see a little of his pictures--and at my; and as his pictures--and--and--and I had\n",
      "Ep 8 (Step 000065): Train loss 2.270, Val loss 6.220\n",
      "Ep 8 (Step 000070): Train loss 1.987, Val loss 6.218\n",
      "Every effort moves you know,\" was one of the picture for a smile that he had the last word.        He laughed again, and, his pictures--and I had been his painting, of, and down the room, in his\n",
      "Ep 9 (Step 000075): Train loss 1.670, Val loss 6.293\n",
      "Ep 9 (Step 000080): Train loss 1.457, Val loss 6.244\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \" to my work, and to me to have to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" she was\n",
      "Ep 10 (Step 000085): Train loss 1.128, Val loss 6.329\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--and I was to have to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" she was\n",
      "Training completed in 5.71 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time() #开始记录时间 （用于计算下面所有代码的执行时间）\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M) #实例化模型\n",
    "model.to(device) #将模型转化到设备上\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr = 0.0002,weight_decay = 0.1) #调用torch的优化器\n",
    "\n",
    "num_epochs = 10 #定义训练轮次数\n",
    "train_losses, val_losses,tokens_seen = train_model_simple(  #调用训练模型\n",
    "    model,train_loader,val_loader,optimizer,device,\n",
    "    num_epochs = num_epochs,eval_freq = 5,eval_iter=5,\n",
    "    start_context = \"Every effort moves you\",tokenizer = tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt      #导入画图的库\n",
    "from matplotlib.ticker import MaxNLocator # 用于将坐标限制为整数\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))  #创建一个5x3的画布，主坐标轴为ax1\n",
    "\n",
    "    # 打印每一轮的训练损失和验证损失\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")   #在右上角添加图例\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  #x轴标签只显示整数\n",
    "\n",
    "    #   再创建一个x轴x2（给token_seen）\n",
    "    ax2 = ax1.twiny()  # 创建一个与x1共享y轴的x2\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  #将第二个坐标轴的y轴坐标隐藏\n",
    "    ax2.set_xlabel(\"Tokens seen\") #添加x轴标签\n",
    "\n",
    "    fig.tight_layout()  #调整布局，使图线不重合\n",
    "    plt.savefig(\"loss-plot.pdf\") #保存图片\n",
    "    plt.show() #绘制出图片\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses)) #创建训练次数的向量，从0到num_epochs，共有len(train_losses)个点\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 相对于官方的代码，我这里降低了学习率..因为在本机上发生了梯度爆炸的问题。\n",
    "- 随着训练的进行，出现了过拟合的现象（指的是在训练集上作用良好，但是在校验集上表现不佳），这是因为现在只是模型“记住”了当前的所有训练序列。\n",
    "- 后续会有一些解码策略，来避免这种过拟合现象的发生\n",
    "- 这里的过拟合现象是因为我们训练集合非常小，重复迭代了多次（出于学习考虑）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.使用解码策略来控制随机性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在使用模型进行推理的阶段，（尤其是小模型）对计算性能的要求远不及训练的时候，所以不一定需要使用到gpu，大部分时候cpu就满足了。\n",
    "- 这里再次使用5.1.2中的简单产生文本函数，这个函数是根据当前字典中最大概率对应的token生成的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know,\" was one of the picture for nothing--I told Mrs.\n",
      "\n",
      "\"I was no--and I was to\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 重复执行上面的代码，模型最后生成的都是同样的输出\n",
    "- 接下来引入两个概念（解码策略），来使得上面的输出文本函数能随机，多样地进行生成\n",
    "- 分为：temperature scaling 和 top-k sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Temperature scaling\n",
    "- 先前我们使用torch.argmax函数来获得最高概率对应的值来作为下一个token\n",
    "- 可以使用` torch.multionmial(probs,num_samples=1)` 来进行采样。它依赖于概率分布，概率越高越有可能被采集到，而不总只是最高值\n",
    "  <br>\n",
    "\n",
    "- 对先前写的产生下一个token的函数进行复习:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = {          #词典表\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}  #反向词典表\n",
    "\n",
    "# Suppose input is \"every effort moves you\", and the LLM\n",
    "# returns the following logits for the next token:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0) #将模型处理后获得的张量归一化，获得概率分布\n",
    "next_token_id = torch.argmax(probas).item()  #直接获取概率最大值所对应的元素\n",
    "\n",
    "# The next generated token is then as follows:\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item() #采用 multionmial 方法来获得下一个词的token id\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用 multinomial函数来对概率分布进行抽样，能获取更多可能的结果，而不仅是最大值\n",
    "- 下面进行1000次采样，来更直观地说明作用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)] #进行multinomal 1000次，并存放到一个列表中\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))# 用于计算每个元素出现的次数\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们可以通过“温度缩放” 来控制概率分布和选择程序\n",
    "- 温度缩放就是指的将logits除以一个大于0的数值\n",
    "- 当温度大于1的时候，将数据平滑，使得能够更好取到概率低的数值\n",
    "- 当温度小于1的时候，加强数据，使得一些数据概率更高，更容易获得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits,temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits,dim=0) #利用温度对logits进行处理\n",
    "\n",
    "temperatures = [1,0.1,5] #设定温度的值--起始值，加强概率，减弱概率\n",
    "\n",
    "#计算 缩放 后的概率\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits,T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#绘制图表\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig,ax = plt.subplots(figsize=(5,3)) #设置图表大小\n",
    "for i,T in enumerate(temperatures):  #进行遍历，用于后续绘制\n",
    "    rects = ax.bar(x+i*bar_width,scaled_probas[i],bar_width,label=f\"Temperature = {T}\")\n",
    "\n",
    "ax.set_ylabel('Probability') #y轴坐标标签\n",
    "ax.set_xticks(x) #x轴刻度位置\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90) #x轴刻度位置上填充关键字，并进行旋转90°\n",
    "ax.legend() #添加图例\n",
    "\n",
    "plt.tight_layout() #紧凑化\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过0.1的温度进行处理，结果接近torch.argmax函数产生的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "992 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "8 x toward\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 x closer\n",
      "68 x every\n",
      "55 x effort\n",
      "223 x forward\n",
      "102 x inches\n",
      "50 x moves\n",
      "43 x pizza\n",
      "218 x toward\n",
      "88 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2]) #而通过5温度处理使得低概率的分布也更容易被选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Top-k 抽样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 为了能够获得多种高温度的词元，并且尽可能避免无异议语句出现的可能 -- 限制每次采样只选择前k 个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits,top_pos = torch.topk(next_token_logits,top_k) #获取前top_k个数据 和他们的索引\n",
    "\n",
    "print(\"Top logits:\",top_logits)\n",
    "print(\"Top positions:\",top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition = next_token_logits < top_logits[-1] , # 判断当前的单词是否小于topk中的最低概率\n",
    "    input = torch.tensor(float(\"-inf\")) , #输入负无穷\n",
    "    other = next_token_logits #否则就是它本身\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "#另一种实现方式\n",
    "new_logits = torch.full_like(\n",
    "    next_token_logits,-torch.inf  #构造一个大小和next_token_logits相同的张量，值全部填充为-inf\n",
    ")\n",
    "new_logits[top_pos] = next_token_logits[top_pos]  #将top_k概率所在的位置赋值\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits,dim=0) #将进行采样过后的数据进行归一化\n",
    "print(topk_probas) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 修改文本生成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens): #每次生成一个词，循环max_new_tokens 次\n",
    "        idx_cond = idx[:, -context_size:] #提取文本的最后 context_size 个数据\n",
    "        with torch.no_grad(): #生成文本，不需要影响梯度（类似于叫校验的时候）\n",
    "            logits = model(idx_cond) #将数据通过模型，获得logits\n",
    "        logits = logits[:, -1, :] #只考虑最后一个数据的logits，用于生成它的下一个单词  形状 （batch_size, num_tokens, vocab） --> (batch_size,vocab_size)\n",
    "        #抽取三维向量中的一个，转化为二维。\n",
    "        \n",
    "        # New: Filter logits with top_k sampling 利用topk采样来过滤 filter\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "            #如果当前的logits 小于 最小topk概率 ，则将其改为-inf（传输到当前设备上）\n",
    "\n",
    "        # New: Apply temperature scaling 应用温度缩放\n",
    "        if temperature > 0.0: #温度必须为正数\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, vocab_size) \n",
    "\n",
    "            # Sample from the distribution 获取下一个token的id\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else: #如果没有设置温度，则按先前的方法，返回最高概率的id\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break #指定了结束id的情况\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1) #将新生成的文本加入原先的文本\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to my with a picture for it was no\n",
      "\"; and\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(  #利用新设置的函数生成文本\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 在pytorch 中保存和加载模型权重\n",
    "- LLM的训练成本很高，所以要考虑到保存和加载已训练过的权重数据\n",
    "- 最推荐的方法是 `state_dict` ,利用torch.save函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"model.pth\") #将模型的数据保存在model.pth文件中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载一个模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M) #实例化一个新的模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #设定当前的设备\n",
    "model.load_state_dict(torch.load(\"model.pth\",map_location = device,weights_only = True)) #加载model.pth中的数据，加载到当前设备上，只加载权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通常使用Adam/AdamW 优化器进行模型训练\n",
    "- 保存的时候加上这些优化器，方便在下一次提取出模型权重的时候，还能继续再进行预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\":optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\",weights_only = True) #加载刚刚保存的数据，用于检查\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M) #实例化一个新模型\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"]) #加载模型权重\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr = 0.0005,weight_decay=0.1) #生成一个新优化器\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"]) #加载刚刚保存拿到优化器\n",
    "model.train() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.从OpenAI 中加载预训练权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 需要先从openai 下载文件并将权重数据导入python\n",
    "- 因为openai使用[TensorFlow](https://www.tensorflow.org/) ，我们需要下载这个库来加载权重。\n",
    "- 使用[tqdm](https://github.com/tqdm/tqdm)（先进的进度条加载库）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow vesion: 2.17.0\n",
      "tqdm version: 4.66.5\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow vesion:\",version(\"tensorflow\"))\n",
    "print(\"tqdm version:\",version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "# 下载124M的参数模型权重\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\",settings)\n",
    "print(\"Parameter dictionary keys:\",params.keys())\n",
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\",params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 模型也可以选择355M，774M，1558M的参数。\n",
    "- 这些导致参数大小区别的因素：嵌入向量的维度，transformer block 循环的次数，多注意力的head数。\n",
    "<br>\n",
    "\n",
    "- 原始的GPT模型使用了不推荐的偏置相，这里为了载入正确的权重矩阵，就需要同样将偏置相设置为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness  \n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy() #拷贝配置\n",
    "NEW_CONFIG.update(model_configs[model_name]) #加入配置\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True}) #加入配置\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG) #实例化一个gpt实例\n",
    "gpt.eval(); #切换为评估模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将openai提供的权重分配到我们的gpt模型中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right): #定义一个重新分配的函数\n",
    "    if left.shape != right.shape:  #如果两边的形状不相同\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\") #返回错误，指出两个向量形状不相同\n",
    "    return torch.nn.Parameter(torch.tensor(right)) #否则返回right包装后的张量（可以后续再进行优化的类型parameter）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt,params): #将权重加载进gpt模型中\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight,params['wpe']) #载入位置嵌入层的权重\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight,params['wte']) #载入token嵌入层的权重\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])): #循环遍历每一层\n",
    "        q_w, k_w, v_w = np.split(  #从给定参数中分离出query,key,value 的权重 ，按列分为3个部分。\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(  #并将这三个权重依次重新分配到gpt模型中\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(   #从给定参数中分离出query,key,value 的偏置\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)  \n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(  #并将它们依次分配到gpt模型中\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(  #提取 c_proj 的输出权重和偏置，并赋给注意力层的输出投影\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign( #将mlp（Multilayer Perceptron）层第一层权重和偏置传入\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(  #将mlp层的输出投影层权重和偏置传入\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(   #传入第一个层归一化（LayerNorm）的缩放和偏移\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(  #传入第二个层归一化的缩放和偏移\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])  #载入输出层的缩放和偏移\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"]) #词嵌入的权重再次用于输出层的权重\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward an equal share for each vote plus half. Inequality is often not an accurate representation of human worth; to know the\n"
     ]
    }
   ],
   "source": [
    "#模型参数已经传入后，利用该模型再次生成文本\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(  \n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
