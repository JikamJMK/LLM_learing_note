{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 指令微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.5.0+cu124\n",
      "tqdm version: 4.66.5\n",
      "tensorflow version: 2.17.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version   #引入本节所需要的库\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",  # Plotting library\n",
    "    \"tiktoken\",    # Tokenizer\n",
    "    \"torch\",       # Deep learning library\n",
    "    \"tqdm\",        # Progress bar\n",
    "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.指令微调引入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 刚预训练结束的模型，相当于“文本补全器”，只会进行补全，而不会遵守某一些指令进行操作\n",
    "- 所以需要加入指令微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本节步骤：\n",
    "- 准备数据集\n",
    "    - 下载训练文本并进行预处理（准备dataset）\n",
    "    - 将dataset 分批\n",
    "    - 创建数据加载器（dataloader）\n",
    "- 微调LLM\n",
    "    - 加载一个预训练过的LLM\n",
    "    - 对LLM进行指令微调\n",
    "    - 检验模型的损失\n",
    "- 评估LLM\n",
    "    - 提取回复\n",
    "    - 定性评估\n",
    "    - 计算回复的分数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.为有监督的指令微调准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json #用于处理json形式的数据\n",
    "import os #用于操作文件和目录\n",
    "import urllib #用于处理url和http请求\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):  #从url 中获得要下载的文件，并保存在file_path这个路径。\n",
    "\n",
    "    if not os.path.exists(file_path):  #如果当前路径下不存在file_path，则从url中下载，并用text_data进行暂存\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data) #然后将text_data 写入该路径中\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file: #将file中的文件，利用json函数进行处理，载入data中。\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url) \n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上述data中的每一元素，都是一个以字典形式存在的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example extry: \n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n",
      "Another extrt: \n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example extry: \\n\",data[50])\n",
    "print(\"Another extrt: \\n\",data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 指令微调也被称为有监督的指令微调，因为训练用的数据中，输入和输出都是精确提供的\n",
    "- 输入输出的格式有多种，例如Alpaca (https://crfm.stanford.edu/2023/03/13/alpaca.html) 和 Phi-3 (https://arxiv.org/abs/2404.14219)\n",
    "- 主要是用于区分输入和输出的形式，方法不一样\n",
    "- 本节我们采用Alpaca-style风格的输入，因为它是指令微调最早的格式模板\n",
    "- 下面将输入进行格式化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry): #格式化输入\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "#如果有输入的情况下，输出格式：\n",
    "model_input = format_input(data[50]) #获得规范化输入\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\" #规范化输出\n",
    "\n",
    "print(model_input + desired_response) #两者合并起来打印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "#如果没有输入的情况下输出：\n",
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 为接下来内容准备训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.将数据组织分配到批次中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 本节将数据处理成等长，放在每一批次中。\n",
    "- 规范：\n",
    "    - 先对输入数据进行规范化处理（按2中的来）\n",
    "    - 将数据进行分词化处理（tokenize），变为token id\n",
    "    - 将分词后的数据加入占位符pad，构成等长的序列\n",
    "    - 创建target的token id 来进行训练\n",
    "    - 将占位符换为空白符。（避免之后计算loss的时候产生影响）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset  #引入torch中的数据集父类\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer): #初始化时传入指令数据和分词器\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [] #将指令数据中的每一项，规范化处理，再加上输出，构成完整长的数据。将这份数据进行分词，编码处理，加入到列表中。\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index): #获得index索引值的解码后数据\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) #返回data数据总长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "#为了加速训练过程，所以我们一个批次内会放入多组数据。这就需要这些数据等长，才能处理。\n",
    "#我们这里利用<|endoftext|>做为占位符进行填充\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\",allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    # and increase the max length by +1, which will add one extra\n",
    "    # padding token below\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = [] #获得一个张量的列表。这里面元素都是张量\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id] #在每个序列最后加上一个占位符，这里是处理的需要。\n",
    "        # Pad sequences to batch_max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * #使得每个数据等长\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # Via padded[:-1], we remove the extra padded token\n",
    "        # that has been added via the +1 setting in batch_max_length\n",
    "        # (the extra padding token will be relevant in later codes)\n",
    "        inputs = torch.tensor(padded[:-1]) #去除掉最后一个添加的占位符\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)  #stack将列表中所有元素堆叠起来，形成张量\n",
    "    return inputs_tensor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = ( #这里最开始的一个批次中，每个数据并不一定等长\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch)) #对数据进行等长化处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目前我们只处理了LLM的输入数据，对于训练过程，我们还需要target value\n",
    "- 这里和预训练一样，采用滑动窗口的方式获得下一个位置的数值，作为下一个token的预测。\n",
    "- 由于target不会取得输入的第一个参数，所以我们需要在每个target最后补上一个占位符，确保target和inputs等长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2( #修改上一个函数，使得它既能够返回输入，又能返回target\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 为了后续计算损失时不受影响，我们需要将target中后面多的占位符全部替换为-100\n",
    "- 此外，我们使用了allowed_max_length来限制样例长度，这里主要是防止当使用自己的训练数据集的时候，文本长度大于GPT2模型所支持的1024长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(  #依旧是对上面的函数进行修改\n",
    "    #第一次我们只考虑了input，第二次加入了target，而这一次是需要将targets中的最后多余占位符换为ignore_index\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id   #返回所有布尔掩码。\n",
    "        indices = torch.nonzero(mask).squeeze() #squeeze消除mask第一维度。这时候indices只有一个维度了。\n",
    "        #nonzero表示返回mask中所有非0元素的索引值。\n",
    "        if indices.numel() > 1: #判断indices中元素数量，由于是张量，所以用numel。\n",
    "            targets[indices[1:]] = ignore_index #保留第一个占位符，其他的全部用ignore_index进行替换。\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device) #将刚刚处理好的列表，转化为最后使用的一个张量。\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 举例表述上述的功能：\n",
    "  - 假定我们现在拥有一些logits(模型最后一层的输出)，用于计算loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [\n",
    "        [-1.0,1.0],\n",
    "        [-0.5,1.5]\n",
    "    ]\n",
    ")\n",
    "targets_1 = torch.tensor([0,1])\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1,targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "#现在当我们再添加一个训练样例，它会影响到最后的输出\n",
    "\n",
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3) \n",
    "#而我们将它的targets改为了-100，此时输出就不变，loss1 == loss3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 默认的，pytorch中corss_entorpy函数有一个参数：ignore_index = -100，表明了在计算交叉熵损失的时候，它会忽视掉-100这个标签。\n",
    "- 所以通过ignore_index的替换，我们就可以实现忽视掉padding的功能。\n",
    "- 但文本结束的第一个pad并不想忽视掉，因为它表明这回复在这里中断。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在实际应用中，通常还需要将指令和输入的部分用mask盖住（同样赋值为ignore_index），只保留需要输出的部分进行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这里直接将获取的数据转移到了device上，而不是在主训练循环中再转移，从而使得使用这个函数来构造数据加载器，效率更高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.为指令数据集创造数据加载器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Device:\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(  #对这个函数调整默认参数，包装成一个新的函数\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(   #实例化一个训练数据加载器\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(  #校验集数据加载器\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(  #测试集数据加载器\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")  #检查一下。此时已经进行过规范化处理了。每一批次，批内单独的长度是一样的。不过对于不同批次，长度还是可能会不同\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如上图所示，每一个批次大小相同。但是长度不同。\n",
    "- 对inputs 和 targets双重检查一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])  #这里的两个都是最后一批次中的。维度为74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.加载一个预训练的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 本节加载一个预训练模型，方法同5.5，6.4中的内容。但是这次加载的是355million的参数，而不是124m，因为指令微调对参数的要求更高，124可能训练不出好的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2 #下载和加载gpt2模型的代码\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt #先前的构造gpt 加载权重的代码。\n",
    "\n",
    "\n",
    "BASE_CONFIG = {  #基础的公有参数\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = { #每个模型不同的参数\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\" #选择355M参数的模型\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL]) #将选择的模型参数加入到基础参数中。\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\") #获得模型大小355（最后括号里的内容。）\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"  #下载gpt2的参数，并且保存到了settings和params中\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG) #实例化一个模型\n",
    "load_weights_into_gpt(model, params) #将刚刚加载出来的参数，传入模型中 。\n",
    "model.eval(); #切换为评估模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在对模型进行微调之前，先看看它在一个校验集数据上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0]) #规范化校验集数据中的第一位。\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")  #引入先前写的产生文本的函数。\n",
    " \n",
    "token_ids = generate( #获得token id \n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer) #将token id 转化为输出文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 注意到先前的生成文本函数，是同时输出了input 和 output\n",
    "- 这里我们只想要作为response的output，所以需要再对文本处理一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = (\n",
    "    generated_text[len(input_text):] #舍去了前面的input内容\n",
    "    .replace(\"### Response:\", \"\")  #删除### Response\n",
    "    .strip() #删除空白字符\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 会发现，模型不能够遵守指令进行操作。他只是重复了一遍输入的内容。（填充了上下文。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.利用指令数据来对模型进行微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这部分使用的损失函数和前面几章节是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 先计算在训练之前，训练集和校验集的损失函数（和前面一样，目标是尽可能地降低损失函数的数值）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8259096145629883\n",
      "Validation loss: 3.7619343280792235\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad(): #禁用梯度\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 进行训练。由于这次的模型是355M的，训练时长要大于124M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
      "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
      "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.534, Val loss 0.730\n",
      "Ep 1 (Step 000075): Train loss 0.567, Val loss 0.731\n",
      "Ep 1 (Step 000080): Train loss 0.602, Val loss 0.727\n",
      "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.712\n",
      "Ep 1 (Step 000090): Train loss 0.566, Val loss 0.693\n",
      "Ep 1 (Step 000095): Train loss 0.502, Val loss 0.685\n",
      "Ep 1 (Step 000100): Train loss 0.506, Val loss 0.680\n",
      "Ep 1 (Step 000105): Train loss 0.568, Val loss 0.673\n",
      "Ep 1 (Step 000110): Train loss 0.558, Val loss 0.668\n",
      "Ep 1 (Step 000115): Train loss 0.513, Val loss 0.664\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.671\n",
      "Ep 2 (Step 000125): Train loss 0.453, Val loss 0.686\n",
      "Ep 2 (Step 000130): Train loss 0.448, Val loss 0.681\n",
      "Ep 2 (Step 000135): Train loss 0.407, Val loss 0.679\n",
      "Ep 2 (Step 000140): Train loss 0.408, Val loss 0.678\n",
      "Ep 2 (Step 000145): Train loss 0.369, Val loss 0.679\n",
      "Ep 2 (Step 000150): Train loss 0.381, Val loss 0.675\n",
      "Ep 2 (Step 000155): Train loss 0.416, Val loss 0.676\n",
      "Ep 2 (Step 000160): Train loss 0.413, Val loss 0.687\n",
      "Ep 2 (Step 000165): Train loss 0.378, Val loss 0.690\n",
      "Ep 2 (Step 000170): Train loss 0.324, Val loss 0.681\n",
      "Ep 2 (Step 000175): Train loss 0.338, Val loss 0.666\n",
      "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.654\n",
      "Ep 2 (Step 000185): Train loss 0.417, Val loss 0.656\n",
      "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.648\n",
      "Ep 2 (Step 000195): Train loss 0.329, Val loss 0.634\n",
      "Ep 2 (Step 000200): Train loss 0.310, Val loss 0.632\n",
      "Ep 2 (Step 000205): Train loss 0.357, Val loss 0.629\n",
      "Ep 2 (Step 000210): Train loss 0.361, Val loss 0.628\n",
      "Ep 2 (Step 000215): Train loss 0.392, Val loss 0.636\n",
      "Ep 2 (Step 000220): Train loss 0.296, Val loss 0.643\n",
      "Ep 2 (Step 000225): Train loss 0.337, Val loss 0.654\n",
      "Ep 2 (Step 000230): Train loss 0.289, Val loss 0.655\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 28.18 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time() #计算开始时间\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1) #设定优化器\n",
    "\n",
    "num_epochs = 2 #训练轮数\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(  #进行训练\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time() #计算结束时间\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可以发现，随着训练的进行，损失值大幅度降低。表明训练效果很好。\n",
    "- 并且回复能够依照指令正确进行\n",
    "- 下面绘制出图表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABZBklEQVR4nO3dd3hUxfrA8e9u6m56LyShRkINoQqxoCBVFCwocgWsVwURsaA/FBGvooKKCqLolVwrigoiIhi60lvoID0BUoCQ3nfn98eBDQshpGzYJLyf59knu+fMnvPOEvLuzJkzo1NKKYQQQghRK+ntHYAQQgghLk8StRBCCFGLSaIWQgghajFJ1EIIIUQtJolaCCGEqMUkUQshhBC1mCRqIYQQohaTRC2EEELUYpKohRBCiFpMErUQ9cjRo0fR6XQkJCTYOxQhhI1IohailtHpdOU+Jk6caO8QhRBXkaO9AxBCWEtOTrY8/+GHH5gwYQL79++3bHN3d7dHWEIIO5EWtRC1THBwsOXh5eWFTqezvA4MDOT9998nLCwMFxcX2rVrx+LFiy97LJPJxMMPP0xUVBSJiYkA/Prrr7Rv3x5XV1eaNGnC66+/TklJieU9Op2OL774gkGDBmE0GomMjGTBggWW/WfPnmXo0KEEBARgMBiIjIxk9uzZl43hp59+ok2bNhgMBvz8/OjZsye5ubmW/V988QUtWrTA1dWVqKgoPvnkE6v3JyUlMXjwYLy9vfH19eXOO+/k6NGjlv0jRoxg4MCBTJ06lZCQEPz8/Bg5ciTFxcUV/syFqNWUEKLWmj17tvLy8rK8fv/995Wnp6f6/vvv1b59+9SLL76onJyc1D///KOUUurIkSMKUNu2bVMFBQVq0KBBKiYmRqWlpSmllFq9erXy9PRUcXFx6tChQ+rPP/9UjRo1UhMnTrScA1BhYWHqu+++UwcOHFCjR49W7u7u6syZM0oppUaOHKnatWunNm3apI4cOaLi4+PVggULyoz/5MmTytHRUb3//vvqyJEjaseOHWrGjBkqOztbKaXUN998o0JCQtTPP/+sDh8+rH7++Wfl6+ur4uLilFJKFRUVqRYtWqiHH35Y7dixQ+3Zs0c98MADqnnz5qqwsFAppdTw4cOVp6eneuKJJ9TevXvVb7/9poxGo5o1a5Zt/zGEsBNJ1ELUYhcn6tDQUPXmm29alenUqZN66qmnlFKlifqvv/5SPXr0UDfccIPKyMiwlO3Ro4d66623rN7/9ddfq5CQEMtrQL3yyiuW1zk5OQpQf/zxh1JKqQEDBqiHHnqoQvFv2bJFAero0aNl7m/atKn67rvvrLa98cYbqmvXrpbYmjdvrsxms2V/YWGhMhgMasmSJUopLVE3bNhQlZSUWMrce++96r777qtQjELUdnKNWog6Iisri5MnTxIbG2u1PTY2lu3bt1ttGzJkCGFhYSxfvhyDwWDZvn37dtasWcObb75p2WYymSgoKCAvLw+j0QhA27ZtLfvd3Nzw9PQkLS0NgCeffJK7776brVu30qtXLwYOHEi3bt3KjDk6OpoePXrQpk0bevfuTa9evbjnnnvw8fEhNzeXQ4cO8cgjj/DYY49Z3lNSUoKXl5cl3oMHD+Lh4WF13IKCAg4dOmR53apVKxwcHCyvQ0JC2LlzZzmfphB1hyRqIeqhfv368c0337Bu3TpuvfVWy/acnBxef/117rrrrkve4+rqannu5ORktU+n02E2mwHo27cvx44dY9GiRcTHx9OjRw9GjhzJ1KlTLzmmg4MD8fHxrF27lj///JOPP/6Y8ePHs2HDBsuXgs8//5wuXbpc8r7z8Xbo0IFvv/32kmMHBARUKF4h6jpJ1ELUEZ6enoSGhrJmzRpuvvlmy/Y1a9bQuXNnq7JPPvkkrVu35o477uD333+3lG/fvj379++nWbNm1YolICCA4cOHM3z4cG688UZeeOGFMhM1aEkzNjaW2NhYJkyYQMOGDZk3bx5jx44lNDSUw4cPM3To0DLf2759e3744QcCAwPx9PSsVsxC1FWSqIWoQ1544QVee+01mjZtSrt27Zg9ezYJCQlltjiffvppTCYTt99+O3/88Qc33HADEyZM4PbbbyciIoJ77rkHvV7P9u3b2bVrF//5z38qFMOECRPo0KEDrVq1orCwkIULF9KiRYsyy27YsIFly5bRq1cvAgMD2bBhA6dOnbKUf/311xk9ejReXl706dOHwsJCNm/ezNmzZxk7dixDhw5lypQp3HnnnUyaNImwsDCOHTvGL7/8wosvvkhYWFjVP0wh6ghJ1ELUIaNHjyYzM5PnnnuOtLQ0WrZsyYIFC4iMjCyz/JgxYzCbzfTr14/FixfTu3dvFi5cyKRJk3jnnXdwcnIiKiqKRx99tMIxODs78/LLL3P06FEMBgM33ngjc+bMKbOsp6cnq1evZtq0aWRlZdGwYUPee+89+vbtC8Cjjz6K0WhkypQpvPDCC7i5udGmTRvGjBkDgNFoZPXq1YwbN4677rqL7OxsGjRoQI8ePaSFLa4ZOqWUsncQQgghhCibTHgihBBC1GKSqIUQQohaTBK1EEIIUYtJohZCCCFqMUnUQgghRC0miVoIIYSoxSRRV8GMGTNo1KgRrq6udOnShY0bN9o7JCuTJ0+mU6dOeHh4EBgYyMCBA63WMwZtruSRI0fi5+eHu7s7d999N6mpqVZlEhMT6d+/P0ajkcDAQF544QWr5RABVq5cSfv27XFxcaFZs2bExcVdEs/V/LzefvttdDqd5T5cqH91PXHiBP/617/w8/PDYDDQpk0bNm/ebNmvlGLChAmEhIRgMBjo2bMnBw4csDpGeno6Q4cOxdPTE29vbx555BFycnKsyuzYsYMbb7wRV1dXwsPDeffddy+JZe7cuURFReHq6kqbNm1YtGiRzeppMpl49dVXady4MQaDgaZNm/LGG29w4R2ldbmuq1evZsCAAYSGhqLT6Zg/f77V/tpUt4rEUtW6FhcXM27cONq0aYObmxuhoaEMGzaMkydP1sm61gj7rQdSN82ZM0c5OzurL7/8Uu3evVs99thjytvbW6Wmpto7NIvevXur2bNnq127dqmEhATVr18/FRERoXJycixlnnjiCRUeHq6WLVumNm/erK6//nrVrVs3y/6SkhLVunVr1bNnT7Vt2za1aNEi5e/vr15++WVLmcOHDyuj0ajGjh2r9uzZoz7++GPl4OCgFi9ebClzNT+vjRs3qkaNGqm2bduqZ555pl7WNT09XTVs2FCNGDFCbdiwQR0+fFgtWbJEHTx40FLm7bffVl5eXmr+/Plq+/bt6o477lCNGzdW+fn5ljJ9+vRR0dHRav369eqvv/5SzZo1U0OGDLHsz8zMVEFBQWro0KFq165d6vvvv1cGg0F99tlnljJr1qxRDg4O6t1331V79uxRr7zyinJyclI7d+60SV3ffPNN5efnpxYuXKiOHDmi5s6dq9zd3dWHH35YL+q6aNEiNX78ePXLL78oQM2bN89qf22qW0ViqWpdMzIyVM+ePdUPP/yg9u3bp9atW6c6d+6sOnToYHWMulLXmiCJupI6d+6sRo4caXltMplUaGiomjx5sh2jKl9aWpoC1KpVq5RS2n8MJycnNXfuXEuZvXv3KkCtW7dOKaX9x9Lr9SolJcVSZubMmcrT09OyDvCLL76oWrVqZXWu++67T/Xu3dvy+mp9XtnZ2SoyMlLFx8erm2++2ZKo61tdx40bp2644YbL7jebzSo4OFhNmTLFsi0jI0O5uLio77//Ximl1J49exSgNm3aZCnzxx9/KJ1Op06cOKGUUuqTTz5RPj4+lvqfP3fz5s0trwcPHqz69+9vdf4uXbqof//739Wr5Dn9+/dXDz/8sNW2u+66Sw0dOrTe1fXi5FWb6laRWKpT17Js3LhRAerYsWN1uq62Il3flVBUVMSWLVvo2bOnZZter6dnz56sW7fOjpGVLzMzEwBfX18AtmzZQnFxsVU9oqKiiIiIsNRj3bp1tGnThqCgIEuZ3r17k5WVxe7duy1lLjzG+TLnj3E1P6+RI0fSv3//S+Kpb3VdsGABHTt25N577yUwMJCYmBg+//xzy/4jR46QkpJiFYeXlxddunSxqq+3tzcdO3a0lOnZsyd6vZ4NGzZYytx00004Oztb1Xf//v2cPXvWUqa8z6S6unXrxrJly/jnn38AbcnLv//+2zL9aH2q68VqU90qEoutZWZmotPp8Pb2rvd1rQhJ1JVw+vRpTCaT1R90gKCgIFJSUuwUVfnMZjNjxowhNjaW1q1bA5CSkoKzs7PlP8F5F9YjJSWlzHqe31demaysLPLz86/a5zVnzhy2bt3K5MmTL9lX3+p6+PBhZs6cSWRkJEuWLOHJJ59k9OjR/O9//7OKt7w4UlJSCAwMtNrv6OiIr6+vTT4TW9X3pZde4v777ycqKgonJydiYmIYM2aMZaWt+lTXi9WmulUkFlsqKChg3LhxDBkyxDKfe32ta0XJohz13MiRI9m1axd///23vUOpEUlJSTzzzDPEx8dbradcX5nNZjp27Mhbb70FQExMDLt27eLTTz9l+PDhdo7Otn788Ue+/fZbvvvuO1q1akVCQgJjxowhNDS03tVVaIqLixk8eDBKKWbOnGnvcGoNaVFXgr+/Pw4ODpeMGE5NTSU4ONhOUV3eqFGjWLhwIStWrLBaDjA4OJiioiIyMjKsyl9Yj+Dg4DLreX5feWU8PT0xGAxX5fPasmULaWlptG/fHkdHRxwdHVm1ahUfffQRjo6OBAUF1Zu6AoSEhNCyZUurbS1atCAxMdEq3vLiCA4OJi0tzWp/SUkJ6enpNvlMbFXfF154wdKqbtOmDQ8++CDPPvuspeekPtX1YrWpbhWJxRbOJ+ljx44RHx9vtTpafatrZUmirgRnZ2c6dOjAsmXLLNvMZjPLli2ja9eudozMmlKKUaNGMW/ePJYvX07jxo2t9nfo0AEnJyereuzfv5/ExERLPbp27crOnTut/nOc/89zPlF07drV6hjny5w/xtX4vHr06MHOnTtJSEiwPDp27MjQoUMtz+tLXQFiY2MvudXun3/+oWHDhgA0btyY4OBgqziysrLYsGGDVX0zMjLYsmWLpczy5csxm8106dLFUmb16tUUFxdb1bd58+b4+PhYypT3mVRXXl4eer31nygHBwfMZnO9q+vFalPdKhJLdZ1P0gcOHGDp0qX4+flZ7a9Pda0Suw1jq6PmzJmjXFxcVFxcnNqzZ496/PHHlbe3t9WIYXt78sknlZeXl1q5cqVKTk62PPLy8ixlnnjiCRUREaGWL1+uNm/erLp27aq6du1q2X/+lqVevXqphIQEtXjxYhUQEFDmLUsvvPCC2rt3r5oxY0aZtyxd7c/rwlHf9a2uGzduVI6OjurNN99UBw4cUN9++60yGo3qm2++sZR5++23lbe3t/r111/Vjh071J133lnmbT0xMTFqw4YN6u+//1aRkZFWt7pkZGSooKAg9eCDD6pdu3apOXPmKKPReMmtLo6Ojmrq1Klq79696rXXXrPp7VnDhw9XDRo0sNye9csvvyh/f3/14osv1ou6Zmdnq23btqlt27YpQL3//vtq27ZtlpHOtaluFYmlqnUtKipSd9xxhwoLC1MJCQlWf7MuHMFdV+paEyRRV8HHH3+sIiIilLOzs+rcubNav369vUOyApT5mD17tqVMfn6+euqpp5SPj48yGo1q0KBBKjk52eo4R48eVX379lUGg0H5+/ur5557ThUXF1uVWbFihWrXrp1ydnZWTZo0sTrHeVf787o4Ude3uv7222+qdevWysXFRUVFRalZs2ZZ7TebzerVV19VQUFBysXFRfXo0UPt37/fqsyZM2fUkCFDlLu7u/L09FQPPfSQys7Otiqzfft2dcMNNygXFxfVoEED9fbbb18Sy48//qiuu+465ezsrFq1aqV+//13m9UzKytLPfPMMyoiIkK5urqqJk2aqPHjx1v98a7LdV2xYkWZ/0+HDx9e6+pWkViqWtcjR45c9m/WihUr6lxda4JOqQum+RFCCCFErSLXqIUQQohaTBK1EEIIUYtJohZCCCFqMUnUQgghRC0miVoIIYSoxSRRCyGEELWYJOoqKiwsZOLEiRQWFto7lBp3LdUVrq36Sl3rr2upvvW9rnIfdRVlZWXh5eVFZmam1Zy09dG1VFe4tuorda2/rqX61ve6SotaCCGEqMUkUQshhBC12DW3HnVJSQnbtm0jKCjokpV5KiM7OxuAEydOkJWVZavwaqVrqa5wbdVX6lp/XUv1rYt1NZvNpKamEhMTg6Nj+an4mrtGvWnTJjp37mzvMIQQQgg2btxIp06dyi1zzbWog4KCAO3DCQkJsXM0QgghrkXJycl07tzZkpPKc80l6vPd3SEhIYSFhdk5GiGEENeyilyClcFkQgghRC0miVoIIYSoxSRRCyGEELXYNXeNWgghymMymSguLrZ3GKKOc3JywsHBwSbHkkRdDbtOZHIyI5/ocG+CPF3tHY4QohqUUqSkpJCRkWHvUEQ94e3tTXBwMDqdrlrHkURdDZMW7mHjkXSmPxDD7W1D7R2OEKIazifpwMBAjEZjtf+4imuXUoq8vDzS0tIAqn0rsCTqarhZbaaLQwK6kzqQRC1EnWUymSxJ2s/Pz97hiHrAYDAAkJaWRmBgYLW6wWUwWTXcmL+M55x+wi1ti71DEUJUw/lr0kaj0c6RiPrk/O9Tdcc8SKKuBpOrr/YkL92+gQghbEK6u4Ut2er3SRJ1dRh8ANAXSKIWQghRMyRRV4PeTbuW5VSUYd9AhBDChho1asS0adMqXH7lypXodLoaHzEfFxeHt7d3jZ6jNrJrop48eTKdOnXCw8ODwMBABg4cyP79+8t9T1xcHDqdzurh6mqfW6OcPPwBcCnKtMv5hRDXtov/Fl78mDhxYpWOu2nTJh5//PEKl+/WrRvJycl4eXlV6XyifHYd9b1q1SpGjhxJp06dKCkp4f/+7//o1asXe/bswc3N7bLv8/T0tEro9rqu5OoZAICbKcMu5xdCXNuSk5Mtz3/44QcmTJhg9bfR3d3d8lwphclkuuLaxwABAQGVisPZ2Zng4OBKvUdUnF1b1IsXL2bEiBG0atWK6Oho4uLiSExMZMuW8kdR63Q6goODLY+KLBNWE9y8AwFwN2fb5fxCiGvbhX8Hvby8rP427tu3Dw8PD/744w86dOiAi4sLf//9N4cOHeLOO+8kKCgId3d3OnXqxNKlS62Oe3HXt06n44svvmDQoEEYjUYiIyNZsGCBZf/FXd/nu6iXLFlCixYtcHd3p0+fPlZfLEpKShg9ejTe3t74+fkxbtw4hg8fzsCBAyv1GcycOZOmTZvi7OxM8+bN+frrry37lFJMnDiRiIgIXFxcCA0NZfTo0Zb9n3zyCZGRkbi6uhIUFMQ999xTqXNfLbXqGnVmptaF7OvrW265nJwcGjZsSHh4OHfeeSe7d+++GuFdwt1XS9TeZJNfZLJLDEKImqGUIq+oxC4PpZTN6vHSSy/x9ttvs3fvXtq2bUtOTg79+vVj2bJlbNu2jT59+jBgwAASExPLPc7rr7/O4MGD2bFjB/369WPo0KGkp19+IG1eXh5Tp07l66+/ZvXq1SQmJvL8889b9r/zzjt8++23zJ49mzVr1pCVlcX8+fMrVbd58+bxzDPP8Nxzz7Fr1y7+/e9/89BDD7FixQoAfv75Zz744AM+++wzDhw4wPz582nTpg0AmzdvZvTo0UyaNIn9+/ezePFibrrppkqd/2qpNROemM1mxowZQ2xsLK1bt75suebNm/Pll1/Stm1bMjMzmTp1Kt26dWP37t1lri9dWFhIYWGh5XV2tu1av0Yv7Rq1m66Q45mZhAWU/wVDCFF35BebaDlhiV3OvWdSb4zOtvnzPGnSJG677TbLa19fX6Kjoy2v33jjDebNm8eCBQsYNWrUZY8zYsQIhgwZAsBbb73FRx99xMaNG+nTp0+Z5YuLi/n0009p2rQpAKNGjWLSpEmW/R9//DEvv/wygwYNAmD69OksWrSoUnWbOnUqI0aM4KmnngJg7NixrF+/nqlTp3LLLbeQmJhIcHAwPXv2xMnJiYiICDp37gxAYmIibm5u3H777Xh4eNCwYUNiYmIqdf6rpda0qEeOHMmuXbuYM2dOueW6du3KsGHDaNeuHTfffDO//PILAQEBfPbZZ2WWnzx5Ml5eXpZHy5YtbRazztWbknMfYXb6KZsdVwghbKVjx45Wr3Nycnj++edp0aIF3t7euLu7s3fv3iu2qNu2bWt57ubmhqenp2WKzLIYjUZLkgZtGs3z5TMzM0lNTbUkTQAHBwc6dOhQqbrt3buX2NhYq22xsbHs3bsXgHvvvZf8/HyaNGnCY489xrx58ygpKQHgtttuo2HDhjRp0oQHH3yQb7/9lry8vEqd/2qpFS3qUaNGsXDhQlavXl1mq7g8Tk5OxMTEcPDgwTL3v/zyy4wdO9by+sSJE7ZL1jod2TpPfFQGuRlpQHPbHFcIYXcGJwf2TOptt3PbysUDc59//nni4+OZOnUqzZo1w2AwcM8991BUVFTucZycnKxe63Q6zGZzpcrbsku/IsLDw9m/fz9Lly4lPj6ep556iilTprBq1So8PDzYunUrK1eu5M8//2TChAlMnDiRTZs21bpbwOzaolZKMWrUKObNm8fy5ctp3LhxpY9hMpnYuXPnZSc9d3FxwdPT0/Lw8PCobthWch08ASjIvPw3SyFE3aPT6TA6O9rlUZN3sqxZs4YRI0YwaNAg2rRpQ3BwMEePHq2x85XFy8uLoKAgNm3aZNlmMpnYunVrpY7TokUL1qxZY7VtzZo1Vo0xg8HAgAED+Oijj1i5ciXr1q1j586dADg6OtKzZ0/effddduzYwdGjR1m+fHk1alYz7NqiHjlyJN999x2//vorHh4epKSkANo/4vkJzYcNG0aDBg2YPHkyoF1vuf7662nWrBkZGRlMmTKFY8eO8eijj9qlDqdcG5GVpSOr8PLfLIUQoraIjIzkl19+YcCAAeh0Ol599dVyW8Y15emnn2by5Mk0a9aMqKgoPv74Y86ePVupLykvvPACgwcPJiYmhp49e/Lbb7/xyy+/WEaxx8XFYTKZ6NKlC0ajkW+++QaDwUDDhg1ZuHAhhw8f5qabbsLHx4dFixZhNptp3rz29YzaNVHPnDkTgO7du1ttnz17NiNGjAC0C/56fWnD/+zZszz22GOkpKTg4+NDhw4dWLt2rU2vPVfGvMjJfLXuGE+7NKOfXSIQQoiKe//993n44Yfp1q0b/v7+jBs3jqysrKsex7hx40hJSWHYsGE4ODjw+OOP07t370qtMjVw4EA+/PBDpk6dyjPPPEPjxo2ZPXu2Jad4e3vz9ttvM3bsWEwmE23atOG3337Dz88Pb29vfvnlFyZOnEhBQQGRkZF8//33tGrVqoZqXHU6dbUvGtjZ8ePHCQ8PJykpqdLXw8vyQfw/fLjsAEO7RPDmoDY2iFAIcbUVFBRw5MgRGjdubLeZDq91ZrOZFi1aMHjwYN544w17h2MT5f1eVSYX1YrBZHWZr5szAGfzyh+IIYQQotSxY8f4888/ufnmmyksLGT69OkcOXKEBx54wN6h1TqSqKupdfoSljl/wMETHYFv7B2OEELUCXq9nri4OJ5//nmUUrRu3ZqlS5fSokULe4dW60iiriZPRzNN9cmcLkq+cmEhhBCAduvUxSO2RdkkUVeTuemt3LfqVQodg5lv72CEEELUO5Koq8kzMIINqgWOedrN/PZayUsIIUT9VGumEK2rfIzaYLISsyK7sMTO0QghhKhvpEVdTa46Ew87L8XdlMXZ7BvwdJWF04UQQtiOJOrq0umZoP8S9LAz/SUIkEQthBDCdqTru7ocHMnRaZPeawtzCCGEELYjidoGch20VnRe5mk7RyKEEJXXvXt3xowZY3ndqFEjpk2bVu57dDod8+fPr/a5bXWc8kycOJF27drV6DlqkiRqG8h31BJ1cbYkaiHE1TNgwAD69OlT5r6//voLnU7Hjh07Kn3cTZs28fjjj1c3PCuXS5bJycn07dvXpueqbyRR20CRszcAppwz9g1ECHFNeeSRR4iPj+f48eOX7Js9ezYdO3akbdu2lT5uQEAARqPRFiFeUXBwMC4uLlflXHWVJGobMLv6aE/yJFELIa6e22+/nYCAAOLi4qy25+TkMHfuXB555BHOnDnDkCFDaNCgAUajkTZt2vD999+Xe9yLu74PHDjATTfdhKurKy1btiQ+Pv6S94wbN47rrrsOo9FIkyZNePXVVykuLga05SZff/11tm/fjk6nQ6fTWWK+uOt7586d3HrrrRgMBvz8/Hj88cfJycmx7B8xYgQDBw5k6tSphISE4Ofnx8iRIy3nqgiz2cykSZMICwvDxcWFdu3asXjxYsv+oqIiRo0aRUhICK6urjRs2NCy1LJSiokTJxIREYGLiwuhoaGMHj26wueuChn1bQPK4AuAvuCsnSMRQthcUW7l3+PgAg7n/ryaSsBUCDo9OBmufFxntwqfxtHRkWHDhhEXF8f48eMtEy7NnTsXk8nEkCFDyMnJoUOHDowbNw5PT09+//13HnzwQZo2bUrnzp2veA6z2cxdd91FUFAQGzZsIDMz0+p69nkeHh7ExcURGhrKzp07eeyxx/Dw8ODFF1/kvvvuY9euXSxevNiyVrSX16V3yOTm5tK7d2+6du3Kpk2bSEtL49FHH2XUqFFWX0ZWrFhBSEgIK1as4ODBg9x33320a9eOxx57rEKf24cffsh7773HZ599RkxMDF9++SV33HEHu3fvJjIyko8++ogFCxbw448/EhERQVJSEklJSQD8/PPPfPDBB8yZM4dWrVqRkpLC9u3bK3TeqpJEbQMO7v4AOBZm2DcQIYTtvRVa+ffcGwetBmnP9/0Gc0dAwxvgod9Ly0xrU3Yv3MTMSp3q4YcfZsqUKaxatcqyDvPs2bO5++678fLywsvLi+eff95S/umnn2bJkiX8+OOPFUrUS5cuZd++fSxZsoTQUO2zeOutty65rvzKK69Ynjdq1Ijnn3+eOXPm8OKLL2IwGHB3d8fR0ZHg4ODLnuu7776joKCAr776Cjc37QvL9OnTGTBgAO+88w5BQUEA+Pj4MH36dBwcHIiKiqJ///4sW7aswol66tSpjBs3jvvvvx+Ad955hxUrVjBt2jRmzJhBYmIikZGR3HDDDeh0Oho2bGh5b2JiIsHBwfTs2RMnJyciIiIq9DlWh3R924Cjux8AriUZ9g1ECHHNiYqKolu3bnz55ZcAHDx4kL/++otHHnkEAJPJxBtvvEGbNm3w9fXF3d2dJUuWkJiYWKHj7927l/DwcEuSBujatesl5X744QdiY2MJDg7G3d2dV155pcLnuPBc0dHRliQNEBsbi9lsZv/+/ZZtrVq1wsHBwfI6JCSEtLSK3R6blZXFyZMniY2NtdoeGxvL3r17Aa17PSEhgebNmzN69Gj+/PNPS7l7772X/Px8mjRpwmOPPca8efMoKanZWSmlRW0Drl4BABhLKvdNWAhRB/zfycq/x+GCwVFRA7Rj6C5qF43ZWb24LvDII4/w9NNPM2PGDGbPnk3Tpk25+eabAZgyZQoffvgh06ZNo02bNri5uTFmzBiKiopsdv5169YxdOhQXn/9dXr37o2Xlxdz5szhvffes9k5LuTk5GT1WqfTYTabbXb89u3bc+TIEf744w+WLl3K4MGD6dmzJz/99BPh4eHs37+fpUuXEh8fz1NPPWXp0bg4LluRFrUNGM8lag9zNiazsnM0Qgibcnar/MPhgjaQg6O27cLr0+UdtwoGDx6MXq/nu+++46uvvuLhhx+2XK9es2YNd955J//617+Ijo6mSZMm/PPPPxU+dosWLUhKSiI5uXQp3/Xr11uVWbt2LQ0bNmT8+PF07NiRyMhIjh07Zl1dZ2dMJtMVz7V9+3Zyc0uv369Zswa9Xk/z5s0rHHN5PD09CQ0NvWSJzTVr1tCyZUurcvfddx+ff/45P/zwAz///DPp6ekAGAwGBgwYwEcffcTKlStZt24dO3fa7ovXxaRFbQNuPoEAeOuyycwvxtfN2c4RCSGuJe7u7tx33328/PLLZGVlMWLECMu+yMhIfvrpJ9auXYuPjw/vv/8+qampVkmpPD179uS6665j+PDhTJkyhaysLMaPH29VJjIyksTERObMmUOnTp34/fffmTdvnlWZRo0aceTIERISEggLC8PDw+OS27KGDh3Ka6+9xvDhw5k4cSKnTp3i6aef5sEHH7Rcn7aFF154gddee42mTZvSrl07Zs+eTUJCAt9++y0A77//PiEhIcTExKDX65k7dy7BwcF4e3sTFxeHyWSiS5cuGI1GvvnmGwwGg9V1bFuTFrUNOHkEkowfJ5U/6TmF9g5HCHENeuSRRzh79iy9e/e2up78yiuv0L59e3r37k337t0JDg5m4MCBFT6uXq9n3rx55Ofn07lzZx599FHefPNNqzJ33HEHzz77LKNGjaJdu3asXbuWV1991arM3XffTZ8+fbjlllsICAgo8xYxo9HIkiVLSE9Pp1OnTtxzzz306NGD6dOnV+7DuILRo0czduxYnnvuOdq0acPixYtZsGABkZGRgDaC/d1336Vjx4506tSJo0ePsmjRIvR6Pd7e3nz++efExsbStm1bli5dym+//Yafn59NY7yQTil1TfXVHj9+nPDwcJKSkggLC7PZcbtPWcHRM3nMfaIrnRr52uy4QoiaV1BQwJEjR2jcuDGurq72DkfUE+X9XlUmF0mL2kZ8znV3p+faboCGEEIIIYnaRnyNWqI+K4laCCGEDUmitpEnMt5jufNYDCf+tncoQggh6hFJ1Dbibz5NE30KZCVfubAQQghRQXZN1JMnT6ZTp054eHgQGBjIwIEDrWafuZy5c+cSFRWFq6srbdq0YdGiRVch2vJtaTaaewsnsNmpg71DEUIIUY/YNVGvWrWKkSNHsn79euLj4ykuLqZXr15WN7tfbO3atQwZMoRHHnmEbdu2MXDgQAYOHMiuXbuuYuSXMoW0Y5OK4njh1VkaTghhe7ac3UoIW/0+2XXCkwuXFQNtKbTAwEC2bNnCTTfdVOZ7PvzwQ/r06cMLL7wAwBtvvEF8fDzTp0/n008/rfGYL8fn3GCy9LyKL7UmhKgdnJ2d0ev1nDx5koCAAJydnS0zewlRWUopioqKOHXqFHq9Hmfn6k2CVatmJsvM1ObK9vW9/H3I69atY+zYsVbbevfubbWeqT2ElBznQYc/ITMQiL1ieSFE7aHX62ncuDHJycmcPFmFub2FKIPRaCQiIgK9vnqd17UmUZvNZsaMGUNsbCytW7e+bLmUlJRLppILCgoiJSWlzPKFhYUUFpbOFpadnW2bgC8SmL2HN5ziWF/YGhh/xfJCiNrF2dmZiIgISkpKrjgntRBX4uDggKOjo016ZmpNoh45ciS7du3i779te3vT5MmTef311216zLKcn+/bU2VTVGLG2VEG1AtR1+h0OpycnGpsFSQhqqJWZJNRo0axcOFCVqxYccWp1IKDg0lNTbXalpqaetnFyF9++WUyMzMtjz179tgs7gsZvbRE7aPLJiNPJj0RQghhG3ZN1EopRo0axbx581i+fDmNGze+4nu6du3KsmXLrLbFx8eXuZA5gIuLC56enpaHh4eHTWK/mN5Nu67uQzbpkqiFEELYiF27vkeOHMl3333Hr7/+ioeHh+U6s5eXFwaDtnbrsGHDaNCgAZMnTwbgmWee4eabb+a9996jf//+zJkzh82bNzNr1iy71QMAg5aoXXXFZGRmQrCnfeMRQghRL9i1RT1z5kwyMzPp3r07ISEhlscPP/xgKZOYmGi1YHm3bt347rvvmDVrFtHR0fz000/Mnz+/3AFoV4WLByXnvvfknj1l31iEEELUG3ZtUVdkhc2VK1desu3ee+/l3nvvrYGIqkGnI9fBEy9TOvlZafaORgghRD1RKwaT1Rf5jl4AFGedtnMkQggh6gtJ1DZU7OwNQEnOGfsGIoQQot6QRG1DJa4+2pP8dPsGIoQQot6QRG1L50Z+6yVRCyGEsBFJ1Dakd/MDwKnorJ0jEUIIUV9IorYhB+9Qjit/zhZXb6UUIYQQ4rxaM9d3fWDu+Dg3rYjE1axnuL2DEUIIUS9Ii9qGfNy0ifwLis3kF8nqO0IIIapPErUNubs44uSgLWkm830LIYSwBen6tiFddgq/OE9AbyribO5fNPA22DskIYQQdZy0qG3J0YU26gCt9Mc4m5Vj72iEEELUA9KitiVXb97zfY11yYph+SX2jkYIIUQ9IC1qW9LrOezfnc0qijP5ZntHI4QQoh6QRG1jvkbtHuqzuTKYTAghRPVJ17eNRRdvQ++wCYd0M9Dc3uEIIYSo46RFbWNdUn/kdaf/4Z++zd6hCCGEqAckUduYsizMIfN9CyGEqD5J1Damd5eFOYQQQtiOJGobczyXqF2KMuwbiBBCiHpBErWNuXoGAGA0ZaKUsnM0Qggh6jpJ1DZm8NIStRc55BTKpCdCCCGqp0qJOikpiePHj1teb9y4kTFjxjBr1iybBVZXuZxrUfuQTbrcSy2EEKKaqpSoH3jgAVasWAFASkoKt912Gxs3bmT8+PFMmjTJpgHWOedGffvoJFELIYSoviol6l27dtG5c2cAfvzxR1q3bs3atWv59ttviYuLs2V8dY9RS9Re5HI2t8DOwQghhKjrqpSoi4uLcXFxAWDp0qXccccdAERFRZGcnGy76Oqicy1qB50iO+OMnYMRQghR11UpUbdq1YpPP/2Uv/76i/j4ePr06QPAyZMn8fPzq/BxVq9ezYABAwgNDUWn0zF//vxyy69cuRKdTnfJIyUlpSrVqBmOzhTojQAUZJ6yczBCCCHquiol6nfeeYfPPvuM7t27M2TIEKKjowFYsGCBpUu8InJzc4mOjmbGjBmVOv/+/ftJTk62PAIDAyv1/pqW7+gFQFH2aTtHIoQQoq6r0qIc3bt35/Tp02RlZeHj42PZ/vjjj2M0Git8nL59+9K3b99Knz8wMBBvb+9Kv+9qyTWEkFtYTF5+vr1DEUIIUcdVqUWdn59PYWGhJUkfO3aMadOmsX///qvSum3Xrh0hISHcdtttrFmzpsbPV1kru8ZxQ+FHbKGlvUMRQghRx1UpUd9555189dVXAGRkZNClSxfee+89Bg4cyMyZM20a4IVCQkL49NNP+fnnn/n5558JDw+ne/fubN269bLvKSwsJCsry/LIzs6usfjO83U7tyZ1ntyeJYQQonqqlKi3bt3KjTfeCMBPP/1EUFAQx44d46uvvuKjjz6yaYAXat68Of/+97/p0KED3bp148svv6Rbt2588MEHl33P5MmT8fLysjxatqz5Vq6PUUvUch+1EEKI6qpSos7Ly8PDwwOAP//8k7vuugu9Xs/111/PsWPHbBrglXTu3JmDBw9edv/LL79MZmam5bFnz54aj6nhyd+Z7/wq9+d8VePnEkIIUb9VKVE3a9aM+fPnk5SUxJIlS+jVqxcAaWlpeHp62jTAK0lISCAkJOSy+11cXPD09LQ8zn/BqEkeKpt2+kOElSRhMsvCHEIIIaquSqO+J0yYwAMPPMCzzz7LrbfeSteuXQGtdR0TE1Ph4+Tk5Fi1ho8cOUJCQgK+vr5ERETw8ssvc+LECcv18GnTptG4cWNatWpFQUEBX3zxBcuXL+fPP/+sSjVqjGvLvjy6+AxJKoDr84vxOXfNWgghhKisKiXqe+65hxtuuIHk5GTLPdQAPXr0YNCgQRU+zubNm7nlllssr8eOHQvA8OHDiYuLIzk5mcTERMv+oqIinnvuOU6cOIHRaKRt27YsXbrU6hi1gZN/EzY4dyG7oIT0vCJJ1EIIIapMp6q5aPL5VbTCwsJsElBNO378OOHh4SQlJdVozDdPWcGxM3n89ERXOjbyrbHzCCGEqHsqk4uqdI3abDYzadIkvLy8aNiwIQ0bNsTb25s33ngDs9lcpaDrleIC7tSvYbjDEtJzCu0djRBCiDqsSl3f48eP57///S9vv/02sbGxAPz9999MnDiRgoIC3nzzTZsGWecoE2Ozp4AT/JT1FHD5wW5CCCFEeaqUqP/3v//xxRdfWFbNAmjbti0NGjTgqaeekkTtZKRY54yTKiI/Mw2IsndEQggh6qgqdX2np6cTFXVp8omKiiI9Pb3aQdV5Oh0FjtptarIwhxBCiOqoUqKOjo5m+vTpl2yfPn06bdu2rXZQ9UGRszcAJTmyJrUQQoiqq1LX97vvvkv//v1ZunSp5R7qdevWkZSUxKJFi2waYF1V4uoLuUCe9DAIIYSouiq1qG+++Wb++ecfBg0aREZGBhkZGdx1113s3r2br7/+2tYx1knKoK0spi+QRC2EEKLqqtSiBggNDb1k0Nj27dv573//y6xZs6odWF2nN/oB4Fh41s6RCCGEqMuq1KIWV+bkoSVql+JMO0cihBCiLpNEXUNcPAMBcDNlUWySSWCEEEJUjSTqGuLq6Q+AD9mczZN1qYUQQlRNpa5R33XXXeXuz8jIqE4s9YreTev69tFlcza3mEAPVztHJIQQoi6qVKL28vK64v5hw4ZVK6B6w6AtxOGjyyEpV1rUQgghqqZSiXr27Nk1FUf9Y/QlT2ck22yQrm8hhBBVJteoa4pfU8Y0/o2+Re+QLi1qIYQQVSSJugb5ujkDcFYStRBCiCqSRF2DfM4l6nTp+hZCCFFFkqhr0KDj7/Kr8ysUHF5v71CEEELUUZKoa1AjcxLR+sNkpB7j8Kkce4cjhBCiDpJEXYOce45nWsAkNpub89OW4/YORwghRB0kibomNenOdTcN5hTe/LL1BCazsndEQggh6hhJ1DWsR4tAvI1OpGQV8NeBU/YORwghRB0jibqGuRxZwS9u7+BCEXOl+1sIIUQlSaKuSUV58OtImmRv5hXHb4jfnUqG3KolhBCiEiRR1yRnIwyaCcCDjkvprjbwa8JJOwclhBCiLrFrol69ejUDBgwgNDQUnU7H/Pnzr/ielStX0r59e1xcXGjWrBlxcXE1Hme1NL0Vuo0G4F2nWazYuNXOAQkhhKhL7Jqoc3NziY6OZsaMGRUqf+TIEfr3788tt9xCQkICY8aM4dFHH2XJkiU1HGk13foqJcHt8Nbl8mT6O+w9cdbeEQkhhKgjKrV6lq317duXvn37Vrj8p59+SuPGjXnvvfcAaNGiBX///TcffPABvXv3rqkwq8/RGcd7v6Rgeixd9PtY8fubtHh8qr2jEkIIUQfUqWvU69ato2fPnlbbevfuzbp16+wUUSX4NeVw59cBuPHkfyk+stbOAQkhhKgL6lSiTklJISgoyGpbUFAQWVlZ5Ofnl/mewsJCsrKyLI/s7OyrEWqZruv1GIt0N+GImZK5j0B+ht1iEUIIUTfUqURdFZMnT8bLy8vyaNmypd1icXTQs7f9axw1B2HIOwm/PQNKZisTQghxeXUqUQcHB5Oammq1LTU1FU9PTwwGQ5nvefnll8nMzLQ89uzZczVCvaw7u0QxungUxcoB9syHrV/ZNR4hhBC1W51K1F27dmXZsmVW2+Lj4+natetl3+Pi4oKnp6fl4eHhUdNhlqtZoDuO4R2YWjJY2/DHOMhIsmtMQgghai+7JuqcnBwSEhJISEgAtNuvEhISSExMBLTW8LBhwyzln3jiCQ4fPsyLL77Ivn37+OSTT/jxxx959tln7RF+ld3bMZxZpv6sceyC6jMZvMK0HQVZUFJo3+CEEELUKnZN1Js3byYmJoaYmBgAxo4dS0xMDBMmTAAgOTnZkrQBGjduzO+//058fDzR0dG89957fPHFF7X71qwy3N42BBcnR4bmjCYhcCDodNqO9TNhSjNYO92u8QkhhKg97Hofdffu3VHlDKYqa9ax7t27s23bthqMquZ5uDrRt3UI87adYO6W48RE+Gg7EtdCYRYYfEoLZ6dA0gYIvx48gso+oBBCiHrLron6WnZvhzDmbTvBb9tPMuH2lrg6OcC/5sHxjRDYorTgzrnw5yvac+8ICOsM4Z0hrBMEtwEHJ/tUQAghxFUhidpOrm/iR5iPgeNn81myO4U72zUAvR4irrcu6OACgS0hbS9kJGqPXT9p+xxdITRGS9oh0drDt6l2HCGEEPWCTpXX91wPHT9+nPDwcJKSkggLC7NrLNOW/sO0pQfwc3MmJsKbCF83GvoZifAz0tDXSJiPEWfHc0m3IAtObIHjmyBpo/azIOPSgzq5QfsHoe87pdtKisDR+arUSQghxJVVJhdJi9qO7u0YzmerDnMmt4ile9Mu2a/XQYiXgXYR3vxfvxY0aHoLNL1F22k2Q/ohLWmf2AzJOyB1NxTngv6Cf9b8szAlEgKj4JGl4OSqbVeqdBCbEEKIWksStR018Dbw17hb2HMyi2PpeSSeyeXYmTwS0/M4diaP/GITJzLyOZGRz+p/TvGfga21LnLQurf9I7VHzFBtm9kEZw5qXeLnpe4GczEUZJYmaYBv79EGqoW0g9B20KADBLcFB/mVEEKI2kS6vmsppRSncgo5lJbLO4v3kZCUAcAd0aG8MbA1XoYKDiJTCjKTICcNwjqWbnun0aVd587uEN4FGnaFhrEQ2t46uQshhLCJyuQiSdR1QInJzPQVB/l4+UFMZkWolytTB0fTral/1Q6oFGSdgJMJkJwAJ7dB0iYozLQu5+CiJfeG3bSBao1uBIO3ti8nTXsY/cAzpBq1E0KIa48k6nLUxUR93rbEszz7QwJHz+Sh08HjNzZhbK/rcHF0qPIxD5/K4eetx/E1ODCiWT4OSevg2Bo4thZyT1kXfnylNsoc4K/3Ydnr0O5fMHCGts1sgs9uAq9w8GsKvk1Kf3qGyWh0IYQ4RwaT1VMxET78PvpG/vP7Hr7fmMRnqw+z+sBppt3XjubBFZ/DvLDExOJdKXy/MZH1h9Mt2+Ob+PLh/cMJ6vJvrdV95tC5pL1Gu/bt4ll6EEdXcAsEV6/SbZlJkLpLe1zMwQXc/LVjuHpq7zv/PHYM+DTUyhVkgU4PLu6V/HSEEKJ+khZ1HRW/J5VxP+8gPbcIJwcdrRt40TrUizYNvGjVwJPIQI/SW7vOOXQqh+83JPLz1uOczSsGtJHlsc382XrsLLlFJvzcnHn/vnbcfF1A5YMqyoOk9VqCTz987uchOHsUzCWXf98TayC4tfZ8zUcQ/yp0fARuf1/bZjZDynbwbw7OxsrHJYQQtYy0qK8Bt7UMIjr8Rl76eSfL96WxLTGDbYkZlv3ODnqiQjxoFepFY38jy/amseFIaes52NOV+zqFM7hTOA28DRw+lcPI77axNzmL4V9u5MnuTXnututwdKhEd7WzEZreqj0uZCqBrOOQd0ZrMRdmWf/0DC0tm3luJTH30ulSVcYxdLO6Y0ZHlmsYzg1aYwxrq00EE9RK61rXV737XwghajNpUddxSimOnsljx/EMdp/MYufxTHadzCS74NIWrF4Ht0YFMqRzBDdfF3BJEi4oNvHm73v5ev0xADo29OGjITGEepe91neNyTv3hcLoS7HJzH+/n8PgAy/gq8spu7yjK/hfpyVtj2Aw+GqD3NrcA44uWpnifHBwloQuhKgVZDBZOepboi6LUoqk9Hx2ntCS9sG0HFqFenJfp3BCvK6cdH/fkcxLP+8gu7AEb6MTU++JpmfLq78gSFZBMSO/3cpfB06j0ylGdvKi6MROTKm7aU4SzfVJXKc7jkFXVPYBXjlVOiPbL4/Djh+h3xTo/Ji2LXk7/P4cOBm0Gd2cDFoyVyatq95s0h4XvlZmuDcOjL7aMXbPg+OboVnP0sloSorg1D7waaRdgxdCiItI1/c1TqfTEXFuKtL+bSt/61T/tiG0aeDFqO+3suN4Jo9+tZkR3Rrx75ubVCjR20JSeh4Px23iQFoORmcHPro/5tyXhRtJzsxnQcJJxm07wT8pmYTr0ojSJdHGJZnYEB1tfEpwNOVbT5ualw4o60VMck9pU7FW1oWt8kPLYetX2m1r5xN1+mH47EbtucFXS9jnH76Nta56/+ba4DqZHU4IcQXSohaXVVhi4p0/9vPlmiOAllNim/pzV/sG9G4VjJtLzXzP25p4lse/2szpnCKCPF347/BOtG7gVWbZvclZzN92gvkJJ0jNKgS0Gd9e7hdF/zYh6M4nwpIibTpVZyO4nBshn3NKW62sKA+Kzz1MRdoUrHpHbfT5+ed6h3NTs+qg1aDSGdz2/Fraom5ys7bt2Dr48cFLb2+7mMFH67L3vw4CmkOHEaWxCSHqNen6Lock6spbvi+VT1cdZuMFg9GMzg70aR3M3e3DuL6JHw5627QMF+44yXM/bqewxEyrUE/+O7wTwV5Xnh3NZFYs2pnM23/s40RGPgCdG/kyYUDLyyb5GleYDWePaaPezx7RfqYf0W51y0gELvyvp4PxyVr3O8DCZ7V72bu/pH0xAO1Yu3/RWunObuBkPNdtb9S+gFz42sWj9l2PLymEjKTSzyI/Q4vX2a20Ps5GbVa882ML8jO0L0/O7nVjxH9eulY3Vy9tDgGAwhxY/h8wFWqfQUnhuedFUFKgXU4x+Gg9LEZ/bXyFm782wZCsQV9vSde3sKlbo4K4NSqIpPQ85m07wS9bj3P0TB6/bD3BL1tPEOLlysCYBtwRHUpUsEdpK7YSlFJ8svIQU5bsB6Bni0A+vD+mwq12B72OAdGh9GwRxKzVh5m56iAbj6YzYPrf3N8pnOd6Ncff3aXScVWLi4d229n5W88uVJSnJezT/8Cp/dqIeKcLLiukH9auc5dccP09bQ8snViJ83uCqzc8tba0pb79B0jbDVEDILyTti0vHRLXlV6rP5/0HV20+98dXbQBew5Ol++qz06FnBTt3vrzM9Wd2g9rP4L0o1ryyjqB9ZeTy3jhcGmiXjoRtsyGW8bDzS9q21J3w6xbzg0O1IPO4Vzvx7mfltfnBksqszYvwEOLtDXdAVa9C+s/gfbD4LZJ2rbcM/DVnefq66Id39FFe68ylY5RUOYLnpvgrs+1SxoAGz6FVe9Ah4dgwDRtm7kENsy8cr0v9uC80kS98ydYNglaDIDeb5aWSdqk3TXhEVz7vpgJm5FELSos3NfI6B6RPH1rM7YmZvDL1uP8tv0kyZkFzFx5iJkrD9E0wI3b24YyIDqEZoHld+MqpThyOpe1h87w555UVv+jdRU/ckNj/q9fiyq10g3ODjzTM5J7O4bx9h/7WLD9JN9vTGLh9mSe6RnJsK6NLrm/3C6cjRDSVnuUpd97WmILaF66zS0Qoh/QuvCLc7WR7JZu+/xzj9zSe9YLs7RWvZNb6TH2/65113uFlybqtD0w54GKxe3oWprEntlR2spdOhG2fwc9X4cbxmjbinJh2zfW73dyK71e7+ZXWoeiHK0eRXnWLWdl0n5eOLbgfIvUVFixmM8zFZc+L87XPkez6YJtuZC6s3LHBMg6WZqoPUPBI1TrITjPyQg3jLVO/hd+CUKnxZJ3GnJPa1/a8s5os/mdl34YMo5Zz89fnA//7ak91zuCR4h2fs8GpT+9Gmg/DT7a74WpSFuz/vxnnH4Y0vZpLfjwzqXHLsrV4r5WxlAopS1cVJxnfbvoyQTtd1ChfTHT6UrXTLiKpOtbVEtBsYkV+9KYt+0EK/85RVGJ2bIvKtiD29uGcHvbUBr5a3+4jp/NY+2hM6w7dIa1h05briuD1iqeeEcrHry+oc3i23Q0ndd/282uE1kAtA3z4uuHu+BlrOCiJnVRSZGWpPMztPnbG3Qo3bfjR+2PT4sB2uIrAMe3wOJx1tfqi/LOJcPLjKgHeG6/1pIDiJ+gtdZjR0PXkdq2gkzY8Jn1YDq3gMr/8VdKe5xvIZcUQU6qFtuFrVxluqC1q7TnqHMtbJ123/35RWZyTmnJ0eirJSnQ6py4Vjv++a5pU+G5Vvq5lrr+3LEsz/UQ1hncqzBBUGXkntF6X1w9tdsQATKPw+x+2k9lKv/9FyprKuA2g+Huz7VtJUXwnwDti4TBR3sYfbV/a68w7Uued8S5n+G1c1yFUtrvcUGm9SMvXev5yU6Fjg9DwHVa+Y2fw6Lnodlt8K+fSo/zn2AoyS997egKr6TaJES5Rl0OSdQ1J6ugmKV7Ulm4I5m/Dpyi2FT6q9UyxJOcwhIS0/Os3uPsoKd9Q2+6NfWnV6sgooJtfzuTyaz4ectxJv+xl7N5xbQL9+abR7vgXkOD4eoVs1lLiJbrqwWlCcwv0npkvbAPU4n2xSXrpNYLk3XigucnIfOE1hJ3cNJa9A/8UJqot/8AG2dB67tKv2DlpMHUyIqf39VbS9p3fw6BLbRt+xfDzrnQKFZLiOfjXD7p3GUU59LeGculFedzX4h0gK70Z1hHcA/UjnHqH21KY88GcF2v0uN+e88FCTlD+1nebIig3WZ5fvzHngXaANCo2+H+b0vLfNwBigvOxYUW56gq3ClSBknU5ZBEfXVk5hWzZHcKv+04ydpDZzCZtV8zB72OtmFedGvqR7em/nRo6IOr09W5trY3OYshn68nI6+Yzo19+d9DnTE4y3U9IawopXV956drvQ75Z7Wu+KyTWus9IwkyE7WfF3bFP7YCGrTXnv/9gXY5pN1QGPiJtq0wByY3qHw8D8wtTcqbZ8PCMdC8Hwz5vrTMG4FlXwrROWgD+84/DN7gHqz1DrS+u/TSU0mh1gNz4TiRGiaDyYTdeRmdGHxuitIzOYWsPnAKL4MTnRr54uFqn27nFiGefP1wFx74fD0bj6Tz+Neb+XxYR5t9UTiVXcj6w2fo0NDn6s/mJoSt6HTaojgu7qWD7y6nMLs0eZ+/Tg/Q+GboPbm0axm0VmnXUed6ZS4c/X5BT835yxVKlf48v7QugF8zaN4fwi64nAMw6FPtmrrruQGU5xOzs1vFLrU4XuWBppUkLWpxzdlyLJ0H/7uRvCITPaICmfmvDlUeYHboVA7xe1KJ35PK1sSzKAVeBidmPNCeGyKruF64EKLek67vckiiFgDrDp1hxOyNFJaY6dcmmI/uj6nQAiRms2Jb0ln+PJecD5/Ktdrv6+ZMem4Reh2M79+Sh2MbVel2NSFE/SZd30JcQdemfswa1pHH/reZRTtTcHHcwdR7o8u8JSwzv5i/D5xmxf40Vu4/xemc0mthTg46rm/iR6+WQfRsGYSP0Znx83bx89bjvLFwD3tOZvHmoNYV6l5Pyyrgs9WH2ZeSxeM3Na3aUqNXsPFIOlP/3M/BtBx83Zzxc3PG390FP3dn/Ny0n/7uzgR7GWjbwAu9jSayEUJUnSRqcc26+boAZgxtz5PfbGHethO4OOqZfFcbAPYmZ7PynzRW7jvFlsSzlsFwAB6ujtzSPJDbWgZxc/MAPC+65j713ra0DPXkzd/38PPW4xw6lcNnD3YgyLPsGdbSsgr4dNVhvt1wjMJzt7etOXiGm64LYHy/FjQPrv7tLwfTsnn7j/0s3Vt6a0l6bhEHy3lPmI+B+zqGc0/HsKs2x7sQ4lK1out7xowZTJkyhZSUFKKjo/n444/p3LlzmWXj4uJ46KGHrLa5uLhQUFBQoXNJ17e42MIdJxn9/TbMCjo39iXxTB4pWda/T80C3el+XQC3RAXSqZFvha5p/33gNCO/20pmfjGBHi589mAHYiJ8LPvTsgv4bNVhvllfmqDbR3jTKtSLOZsSKTYp9Dq4r1M4z952HYEeV55K9WJpWQV8sPQAP2xKxKy0Uff3dQpnSKcIsguLOZNTxJmcQs7kFnH6guf/pGSTXajd3qLXQffmgdzXKZxbowJxqswa5UKIMtWpa9Q//PADw4YN49NPP6VLly5MmzaNuXPnsn//fgIDAy8pHxcXxzPPPMP+/fst23Q6HUFBFZsTVxK1KMvPW47z3NztlteuTnpim/rTPSqQ7tcFEO5btXmmj53J5bGvNvNPag7ODnreuqsNN13nz6xVh/lmwzEKirUEHRPhzbM9r+PGSH90Oh3HzuTyzuJ9LNqZAoCbswNPdm/KIzc0qdAtZTmFJcxafZjPVx8mv1ibDKNXyyBe7BNFs0D3K74/v8jEH7uSmbMpyWqOd393F+7pEMZ9ncJp7O9WzhGEEOWpU4m6S5cudOrUienTpwNgNpsJDw/n6aef5qWXXrqkfFxcHGPGjCEjI6NK55NELS5n8a5ktiVlENvUn86NfW1221ZOYQnP/pBA/B6t29nZQU+RqewEfbFNR9P5z+972Z6UAUCIlytjb7uOpoHuFBabKTKZKSw2UVhipqjETGGJmTM5hfxv3VFO5xRZzvF//VrQqZFvleI/dCqHHzcn8fOW45ZjAgyKacDEAa3q9yxvQtSQOpOoi4qKMBqN/PTTTwwcONCyffjw4WRkZPDrr79e8p64uDgeffRRGjRogNlspn379rz11lu0atWqzHMUFhZSWFg6+OfEiRO0bNlSErW4qsxmxbRlB/ho2QEA2oV78+xt13HTZRL0xe/9bcdJ3l2837IyWEU09nfjxd7N6dM62CYjz4tKzCzfl8qcTUms+ucUSkGQpwvv3N2W7s0v7f0SQlxenRn1ffr0aUwm0yXd1kFBQezbt6/M9zRv3pwvv/yStm3bkpmZydSpU+nWrRu7d+8us7KTJ0/m9ddfr5H4hagovV7H2HOJudikuL6Jb4WTp16v48522hrgX645wo+bkjAphbODHhdHB1yc9Lg46nF2dMDFUXt+fRM/7usUbtPryc6Oevq0DqFP6xC2Jp7luR+3c+R0LiNmb+KBLhGM79eixtYoF+JaZtcW9cmTJ2nQoAFr166la9eulu0vvvgiq1atYsOGDVc8RnFxMS1atGDIkCG88cYbl+yXFrUQNSO/yMQ7i/cRt/YoAOG+BqbeE02XJn72DUyIOqDOtKj9/f1xcHAgNdV6NZLU1FSCg4MrdAwnJydiYmI4eLDsG01cXFxwcSmdHi4rK6vqAQshLAzODky8oxW9Wgbxwk87SErP5/7P1/NIbGOe7938kmv8GXlFHDqVy+FTORw5ncvZvCJcnRwwOjtgdHbE4OSAm4sDBmdHjE4OeBmdaBvmhYujzMcurm12TdTOzs506NCBZcuWWa5Rm81mli1bxqhRoyp0DJPJxM6dO+nXr18NRiqEuJxuzfxZPOZG3li4hx83H+eLv4+w8p9TDGwXyrEzeRw+rSXns3nFVz7YRbwMTvRvG8LAdg3o2NBHJmAR1yS7X1AaO3Ysw4cPp2PHjnTu3Jlp06aRm5truVd62LBhNGjQgMmTJwMwadIkrr/+epo1a0ZGRgZTpkzh2LFjPProo/ashhDXNA9XJ969J5rerYJ56ZedHEzLYeqf/1xSLsTLlSYBbjT2dyPA3ZWCEhP5RSbyikrIKzr/3EResYkTZ/M4nVPEdxsS+W5DIg28DdzZLpRBMQ2IDKqFayDXYWazki9BtZjdE/V9993HqVOnmDBhAikpKbRr147FixdbBpglJiai15cOiDl79iyPPfYYKSkp+Pj40KFDB9auXUvLli3tVQUhxDk9WgTx5xgfpq84yOmcQpr4u9MkwM2SnI3OFf+TYzIr1h8+w7xtJ1i8K4UTGfl8svIQn6w8RKtQTwa2a0AjfzfMSqGUwqzAfO6n9loR4mWgY0OfCs3jXlH5RSbWHDzNsn1prP7nFFkFxdpgPgc9zo56nM79dD63LdDT1TJZjq+b/dfvLjGZ2ZeSzdbEs2w9dpatiRmkZBVwb4cwXu7XQtZpr4Xsfh/11Sb3UQtR9xQUm1i6N5X5206ycn8aJeaK/9nyc3Omd+tg+rcJoUtj3yol7eTMfJbtTWP5vjTWHDxtmUmuMnQ6aB/hQ48WgfSICuK6IPersmBLbmEJ6w6d0RJz4lm2J2VaJsG5WJiPgXfvaUu3pnVv5bfUrAKKTWbCfKo2OdHVVmfuo7YHSdRC1G3puUX8vjOZP3enkF1Qgl4Hep0OvU6HTqdNk6o/lwB3n8y0ujZeXtJWSpFVUEJqVgEpmQWkZBVw9HQuK/efYk+y9SDUBt4GerQI5NaoQCJ8jRSZtAlnLA9T6c/9Kdks25t2yTHCfAz0iAqkR4sgbmjmb/Ou5zM5hcStPcr/1h4lq6DEap+HqyPtwr1pH+FD+4Y+mJXi1fm7OH5Wu09/eNeGjOsbVakekKstu6CYDYfT+fvgaf4+eJqDaTk46HW8NqAlw7o2snd4VySJuhySqIW4dhSbzKw/fIbfdySzZHfKJUm7UyNfMvKLSM0qJCWz4LItzfOt4VujAunZomqt4ZMZ+SzfV3arvEmAG0/c3JSB7RpUeW30805k5PP56sPM2ZRomaI23NdA1yZ+lsTcLMD9ki8GOYUlTF60l283JAIQ4Wtkyj1ta83tdkUlZrYfz+DvA1piTkjKsFos50IPXt+Q1wa0tOklD1uTRF0OSdRCXJvOJ+1FO5NZvCvlsqPQPV0dCfZyJcjTlRAvV7o09qN78wD83F3KLF8VF17n/n3HSUuLN8TLlUdvbMKQzuGVbs0eSM1m5qpDLEg4abk00DbMi6e6N6VXy+AKt9j/OnCKcT/t4GRmATodjOjWiBd7R1VojvmqKCoxE78nlUW7ksnMKya/WBtUeP5nXlEJBeemy71YIz8jsc38uTHSn+ub+PH9xiTeXbIPpeDGSH+mP9AeL0PtnOJWEnU5JFELIc4n7f0p2fi7uxDk6UqwlyvBnq41lpAuJ7ugmO83JvLFX0dIy9YmZ/IxOjGiW2OGd2uIt7HsAWj5RSZOZuaTeCaP7zcm8uee0vkoYpv58VT3ZnRr6lel6+BZBcW89fte5mxKArTpaB+8viFBnq4EeboQ6OFKoKdLtebDT0rX4v5xc5LVHPLl8TE6EdvMnxua+RPbzL/MxXKW7E5hzJwE8otNNAlw48vhnWhUgQVkzg+yC/cxXpX56yVRl0MStRCiNiooNjFv2wk+W3WIo2fyADA6O3B/pwgCPFw4mZFPcmY+JzMKSM7Mv6RHQKeD3i2DebJ7U6LDvW0S04r9abz8885Lln09z9PVkSBPLWk38DbQLNBdewR4EOZjuKQVX2Iys3xfGt9uSGT1AW2+eIAADxfu7RBGZJA7BidHDM7aRDgGJwfLpDgGJwe8DE4V6hnYdSKTx77aTHJmAV4GJz79Vwe6Nr20C18pxe6TWfyy9QQLtp/kdE4hrk56BrZrwINdG9Iq1KvyH1oFSaIuhyRqIURtZjIrFu1MZubKQ5cMQLuYm7MDod4G2kf48NhNjWkWaPv7yzPzi/nv30c4lJZDalYBadmFpGYVXHHku6uTnib+7pbkXWIy8+Pm41ZJ/8ZIf4Z2iaBHiyCbr3OellXAY19vYXtSBo56Hf8Z2Jr7O0cAWmv+14QTzNt2gkOnci3vcXHUW9WrY0MfhnVrRJ9WwdUeO3AxSdTlkEQthKgLlFKs+ucUP205jrODnhBvV0K9DYR6GQjxdiXEy4Cnq+NVucWrrNiyCko4lV1AapaWuBPT8ziQlsOhtBwOn8ot85oygK+bM/d2DGNIp4gKdUlXR0GxiRd+2sFv208C2tKsx8/msenoWUsZF0c9t7UMYlBMA26MDGD78Qz+t/Yoi3elWK71B3i4MKRzBEO7RBDk6WqT2CRRl0MStRBC1CyTWZF0LnEfPPfILSyhX9sQercKuqrztyul+GjZQT5YWjpTnk4H3Zr6MbBdA/q0DsbD9dJr0mlZBXy3MZFvNyRy6tzYAUe9jt6tg3m1f0uCvaqXsCVRl0MStRBCXHv+2JnM95uSuKGZH3dEN6hwoi0qMbNkdwpfrTvKpqNncXdxZP3/9aj2DG51ZvUsIYQQ4mro2yaEvm1CKv0+Z0c9A6JDGRAdyp6TWRw8lXPVp1mVRC2EEEJUQMtQT1qGel7189beaVuEEEIIIYlaCCGEqM0kUQshhBC1mCRqIYQQohaTRC2EEELUYtfcqG+zWZstJzk52c6RCCGEuFadz0Hnc1J5rrlEnZqqrTDTuXNnO0cihBDiWpeamkpERES5Za65mclKSkrYtm0bQUFB6PXV6/nPzs6mZcuW7NmzBw8P20+GL0RtJb/74lpky997s9lMamoqMTExODqW32a+5hK1LWVlZeHl5UVmZiaenlf/Jngh7EV+98W1yF6/9zKYTAghhKjFJFELIYQQtZgk6mpwcXHhtddew8XFxd6hCHFVye++uBbZ6/derlELIYQQtZi0qIUQQohaTBK1EEIIUYtJohZCCCFqMUnU1TBjxgwaNWqEq6srXbp0YePGjfYOSYgatXr1agYMGEBoaCg6nY758+fbOyQhatzkyZPp1KkTHh4eBAYGMnDgQPbv33/Vzi+Juop++OEHxo4dy2uvvcbWrVuJjo6md+/epKWl2Ts0IWpMbm4u0dHRzJgxw96hCHHVrFq1ipEjR7J+/Xri4+MpLi6mV69e5ObmXpXzy6jvKurSpQudOnVi+vTpgDYdXHh4OE8//TQvvfSSnaMToubpdDrmzZvHwIED7R2KEFfVqVOnCAwMZNWqVdx00001fj5pUVdBUVERW7ZsoWfPnpZter2enj17sm7dOjtGJoQQoqZlZmYC4Ovre1XOJ4m6Ck6fPo3JZCIoKMhqe1BQECkpKXaKSgghRE0zm82MGTOG2NhYWrdufVXOec0tcymEEEJU1ciRI9m1axd///33VTunJOoq8Pf3x8HBwbK29XmpqakEBwfbKSohhBA1adSoUSxcuJDVq1cTFhZ21c4rXd9V4OzsTIcOHVi2bJllm9lsZtmyZXTt2tWOkQkhhLA1pRSjRo1i3rx5LF++nMaNG1/V80uLuorGjh3L8OHD6dixI507d2batGnk5uby0EMP2Ts0IWpMTk4OBw8etLw+cuQICQkJ+Pr6EhERYcfIhKg5I0eO5LvvvuPXX3/Fw8PDMhbJy8sLg8FQ4+eX27OqYfr06UyZMoWUlBTatWvHRx99RJcuXewdlhA1ZuXKldxyyy2XbB8+fDhxcXFXPyAhrgKdTlfm9tmzZzNixIiaP78kaiGEEKL2kmvUQgghRC0miVoIIYSoxSRRCyGEELWYJGohhBCiFpNELYQQQtRikqiFEEKIWkwStRBCCFGLSaIWQgghajFJ1EKIGqPT6Zg/f769wxCiTpNELUQ9NWLECHQ63SWPPn362Ds0IUQlyKIcQtRjffr0Yfbs2VbbXFxc7BSNEKIqpEUtRD3m4uJCcHCw1cPHxwfQuqVnzpxJ3759MRgMNGnShJ9++snq/Tt37uTWW2/FYDDg5+fH448/Tk5OjlWZL7/8klatWuHi4kJISAijRo2y2n/69GkGDRqE0WgkMjKSBQsWWPadPXuWoUOHEhAQgMFgIDIy8pIvFkJc6yRRC3ENe/XVV7n77rvZvn07Q4cO5f7772fv3r0A5Obm0rt3b3x8fNi0aRNz585l6dKlVol45syZjBw5kscff5ydO3eyYMECmjVrZnWO119/ncGDB7Njxw769evH0KFDSU9Pt5x/z549/PHHH+zdu5eZM2fi7+9/9T4AIeoCJYSol4YPH64cHByUm5ub1ePNN99USikFqCeeeMLqPV26dFFPPvmkUkqpWbNmKR8fH5WTk2PZ//vvvyu9Xq9SUlKUUkqFhoaq8ePHXzYGQL3yyiuW1zk5OQpQf/zxh1JKqQEDBqiHHnrINhUWop6Sa9RC1GO33HILM2fOtNrm6+tred61a1erfV27diUhIQGAvXv3Eh0djZubm2V/bGwsZrOZ/fv3o9PpOHnyJD169Cg3hrZt21qeu7m54enpSVpaGgBPPvkkd999N1u3bqVXr14MHDiQbt26VamuQtRXkqiFqMfc3Nwu6Yq2FYPBUKFyTk5OVq91Oh1msxmAvn37cuzYMRYtWkR8fDw9evRg5MiRTJ061ebxClFXyTVqIa5h69evv+R1ixYtAGjRogXbt28nNzfXsn/NmjXo9XqaN2+Oh4cHjRo1YtmyZdWKISAggOHDh/PNN98wbdo0Zs2aVa3jCVHfSItaiHqssLCQlJQUq22Ojo6WAVtz586lY8eO3HDDDXz77bds3LiR//73vwAMHTqU1157jeHDhzNx4kROnTrF008/zYMPPkhQUBAAEydO5IknniAwMJC+ffuSnZ3NmjVrePrppysU34QJE+jQoQOtWrWisLCQhQsXWr4oCCE0kqiFqMcWL15MSEiI1bbmzZuzb98+QBuRPWfOHJ566ilCQkL4/vvvadmyJQBGo5ElS5bwzDPP0KlTJ4xGI3fffTfvv/++5VjDhw+noKCADz74gOeffx5/f3/uueeeCsfn7OzMyy+/zNGjRzEYDNx4443MmTPHBjUXov7QKaWUvYMQQlx9Op2OefPmMXDgQHuHIoQoh1yjFkIIIWoxSdRCCCFELSbXqIW4RslVLyHqBmlRCyGEELWYJGohhBCiFpNELYQQQtRikqiFEEKIWkwStRBCCFGLSaIWQgghajFJ1EIIIUQtJolaCCGEqMUkUQshhBC12P8DsimaiOd6uDQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0,num_epochs,len(train_losses)) #x轴分段\n",
    "plot_losses(epochs_tensor,tokens_seen,train_losses,val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 由图可以发现，模型学习速度很快，但是最后出现了一些过拟合现象。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.提取和保存回复"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 先简单地看下微调过的文本产生的回复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]: #看前三组数据\n",
    "\n",
    "    input_text = format_input(entry) #设定输入数据，进行规范化处理。\n",
    "\n",
    "    token_ids = generate( #利用模型，将输入数据传入进行处理\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer) #获得的token id 转化为对应的文本内容。\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):] #去除掉回复前面的input重复部分\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text) #打印输入文本\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\") #打印正确的输出文本\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\") #打印模型产生的输出文本.\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 注意到模型的处理能力非常好.虽然还有一些小问题\n",
    "- 但在这里,对模型的评估就不能像先前一样只是单纯的比较token id 之间的距离了.就像第三个语句那样,可能只是文本数目不同.\n",
    "- 现在比较常用的一些评估方法:\n",
    "  - sMMLU (\"Measuring Massive Multitask Language Understanding\", [https://arxiv.org/abs/2009.03300](https://arxiv.org/abs/2009.03300))\n",
    "  - LMSYS chatbot arena ([https://arena.lmsys.org](https://arena.lmsys.org))\n",
    "  -  AlpacaEval ([https://tatsu-lab.github.io/alpaca_eval/](https://tatsu-lab.github.io/alpaca_eval/))\n",
    "- 我们之后实现的是类似于AlpacaEval的方法,但是是用我们自己的数据集进行的\n",
    "- 为此,我们需要先将微调后的模型进行保存,方便后续再载入."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [02:49<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)): \n",
    "\n",
    "    input_text = format_input(entry)  #将测试集输入全部转化为常规输入输出 + 模型输出的形式\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file: #打开这个文件,并进行写入\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a cheetah.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0]) #检查一下其中一个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "#最后保存一下模型\n",
    "import re\n",
    "\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\" #正则表达式，对CHOOSE_MODEL中的数据进行处理，去除空格,(,) 并在最后加上文件扩展名\n",
    "torch.save(model.state_dict(), file_name) #将模型数据按刚刚设定的名字进行保存\n",
    "print(f\"Model saved as {file_name}\") #保存成功，打印一下名字。\n",
    "\n",
    "# Load model via\n",
    "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.评估微调后的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 本章我们采用一个更大的现有模型来进行评估 -- 用Ollama来运行llama3。 写 ollama rum llama3 ，来运行一个8B 参数的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "#检查当前ollama是否加载成功\n",
    "\n",
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用rest api 来运行代替ollama run 命令（确保此时ollama running 是true）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
      "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
      "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
      "5. Minerals: Llamas need access to mineral supplements, which provide essential nutrients like calcium, phosphorus, and salt.\n",
      "\n",
      "In the wild, llamas might also eat:\n",
      "\n",
      "1. Leaves: They'll munch on leaves from trees and shrubs, like willow, alder, or cedar.\n",
      "2. Bark: In some cases, llamas may eat the bark of certain trees, like aspen or birch.\n",
      "3. Mosses: Llamas have been known to graze on mosses, which are non-vascular plants that grow in dense clusters.\n",
      "\n",
      "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and fruits/vegetables. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "def query_model(  #定义一个查询用模型，参数为llama3模型。\n",
    "    prompt,\n",
    "    model=\"llama3\",\n",
    "    url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # Create the data payload as a dictionary 传入用于询问的文本数据 字典\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {     # Settings below are required for deterministic responses\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    # Convert the dictionary to a JSON formatted string and encode it to bytes 将字典数据转化为格式化字符串，并且编码为二进制\n",
    "    payload = json.dumps(data).encode(\"utf-8\") #创建一个http请求的有效载荷\n",
    "\n",
    "    # Create a request object, setting the method to POST and adding necessary headers \n",
    "    request = urllib.request.Request( #创建一个http post 请求对象\n",
    "        url, #发送请求的地址\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\", \"application/json\") #设置请求头，告诉服务器这是json数据\n",
    "\n",
    "    # Send the request and capture the response 发送请求，并捕获回复\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response: #发送请求，并接受回复为response\n",
    "        # Read and decode the response\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\") #逐行读取回复内容，并且按utf-8格式进行解码\n",
    "            if not line: #如果没有读入，则终止\n",
    "                break\n",
    "            response_json = json.loads(line) #将数据加载为json文件\n",
    "            response_data += response_json[\"message\"][\"content\"] #将json文件中的输出内容部分加载到回复字符串中\n",
    "\n",
    "    return response_data #返回回复的字符串\n",
    "\n",
    "\n",
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用上文定义的查询函数，可以对先前自己微调的模型进行评估。\n",
    "- 先评估前3条"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "\n",
      "Score:\n",
      ">> I'd rate the model response \"The car is as fast as a cheetah.\" an 85 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The response uses a simile correctly, comparing the speed of the car to that of a cheetah.\n",
      "* Cheetahs are known for their incredible speed, making them a relevant and effective comparison for describing a fast car.\n",
      "* The phrase \"as fast as\" is used correctly to introduce the simile.\n",
      "\n",
      "The only reason I wouldn't give it a perfect score is that lightning is often used as a metaphor for extreme speed, so using a cheetah instead of lightning might not be as universally recognized or evocative. However, the response is still effective and clear in conveying the idea that the car is very fast!\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "\n",
      "Score:\n",
      ">> I'd score this model response as 40 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The model correctly identifies that thunderstorms are related to clouds (correctly identifying the type of phenomenon).\n",
      "* However, it incorrectly specifies the type of cloud associated with thunderstorms. Cumulus clouds are not typically associated with thunderstorms; cumulonimbus clouds are.\n",
      "* The response lacks precision and accuracy in its description.\n",
      "\n",
      "Overall, while the model attempts to address the question, it provides an incorrect answer, which is why I'd score it as 40 out of 100.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">> I'd rate my own response as 95 out of 100. Here's why:\n",
      "\n",
      "* The response accurately answers the question by naming the author of 'Pride and Prejudice' as Jane Austen.\n",
      "* The response is concise and clear, making it easy to understand.\n",
      "* There are no grammatical errors or ambiguities that could lead to confusion.\n",
      "\n",
      "The only reason I wouldn't give myself a perfect score is that the response is slightly redundant - it's not necessary to rephrase the question in the answer. A more concise response would be simply \"Jane Austen.\"\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = ( #传入数据\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\") #返回数据集的输出（target）\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\") \n",
    "    print(\">>\", entry[\"model_response\"]) #返回自定义的模型的输出\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt)) #返回最后的评分\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如上文所示，llama3模型返回了一个合适的数值，并进行了解释。不过解释太长了，之后测试的时候，告诉模型只用返回数值即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|███████████████████████████████████████████████████████████████| 110/110 [05:29<00:00,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 48.51\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"   \n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = generate_model_scores(test_data, \"model_response\") #加载进测试数据（一共110条）\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\") #成功加载进入计算的数据\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\") #计算平均分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
